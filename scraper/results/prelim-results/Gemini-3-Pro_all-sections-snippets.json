{
  "Gemini 3 Pro": {
    "sections": [
      {
        "sectionId": "model-details",
        "sectionSnippets": [
          {
            "snippetId": "model-details-snippet-1",
            "url": "https://ai.google.dev/gemini-api/docs/models",
            "snippet": "OUR MOST INTELLIGENT MODEL\n\n## Gemini 3 Pro\n\nThe best model in the world for multimodal understanding, and our most powerful agentic and vibe-coding model yet, delivering richer visuals and deeper interactivity, all built on a foundation of state-of-the-art reasoning.\n\n### Expand to learn more\n\n#### Model details... ### Gemini 3 Pro Preview\n\n|Property|Description|\n|--|--|\n|Model code|`gemini-3-pro-preview`|\n|Supported data types|Text, Image, Video, Audio, and PDF Text|\n|Token limits [*]|1,048,576 65,536|\n|Capabilities|Not supported Supported Supported Supported Supported Supported Not supported Not supported Not supported Supported Supported Supported Supported|\n|Versions||\n|Latest update|November 2025|\n|Knowledge cutoff|January 2025|... ### Gemini 3 Pro Image Preview\n\n|Property|Description|\n|--|--|\n|Model code|`gemini-3-pro-image-preview`|\n|Supported data types|Image and Text Image and Text|\n|Token limits [*]|65,536 32,768|\n|Capabilities|Not supported Supported Not supported Not supported Not supported Not supported Not supported Supported Not supported Supported Supported Supported Not supported|\n|Versions||\n|Latest update|November 2025|\n|Knowledge cutoff|January 2025|\nOUR ADVANCED THINKING MODEL... ### Gemini 2.5 Pro\n\n|Property|Description|\n|--|--|\n|Model code|`gemini-2.5-pro`|\n|Supported data types|Audio, images, video, text, and PDF Text|\n|Token limits [*]|1,048,576 65,536|\n|Capabilities|Not supported Supported Supported Supported Supported Supported Supported Not supported Not supported Supported Supported Supported Supported|\n|Versions||\n|Latest update|June 2025|\n|Knowledge cutoff|January 2025|... ### Gemini 2.5 Pro TTS\n\n|Property|Description|\n|--|--|\n|Model code|`gemini-2.5-pro-preview-tts`|\n|Supported data types|Text Audio|\n|Token limits [*]|8,192 16,384|\n|Capabilities|Supported Not Supported Not supported Not supported Not Supported Not supported Not supported Not supported Not supported Not supported Not supported Not supported Not supported|\n|Versions||\n|Latest update|May 2025|\nFAST AND INTELLIGENT... ### Gemini 2.5 Flash Preview\n\n|Property|Description|\n|--|--|\n|Model code|`gemini-2.5-flash-preview-09-2025`|\n|Supported data types|Text, images, video, audio Text|\n|Token limits [*]|1,048,576 65,536|\n|Capabilities|Not supported Supported Supported Supported Supported Supported Not supported Not supported Not supported Supported Supported Supported Supported|\n|Versions||\n|Latest update|September 2025|\n|Knowledge cutoff|January 2025|... |Versions|gemini-live-2.5-flash-preview will be deprecated on December 09, 2025|\n|Latest update|September 2025|\n|Knowledge cutoff|January 2025|... |Token limits [*]|1,048,576 8,192|\n|Capabilities|Supported Not supported Not supported Supported Not supported Supported Not supported Not supported Supported Supported Supported Not supported Supported|\n|Versions||\n|Latest update|April 2025|\n|Knowledge cutoff|August 2024|\nOUR SECOND GENERATION FAST MODEL... ## Model version name patterns\n\nGemini models are available in either\n\n*stable*, *preview*, *latest*, or\n\n*experimental* versions.\n\n### Stable\n\nPoints to a specific stable model. Stable models usually don't change. Most production apps should use a specific stable model.\n\nFor example:\n\n`gemini-2.5-flash`.... ### Preview\n\nPoints to a preview model which may be used for production. Preview models will typically have billing enabled, might come with more restrictive rate limits and will be deprecated with at least 2 weeks notice.\n\nFor example:\n\n`gemini-2.5-flash-preview-09-2025`.... ### Latest\n\nPoints to the latest release for a specific model variation. This can be a\n\nstable, preview or experimental release. This alias will get hot-swapped with\n\nevery new release of a specific model variation. A\n\n**2-week notice** will\n\nbe provided through email before the version behind latest is changed.\n\nFor example:\n\n`gemini-flash-latest`.... ### Experimental\n\nPoints to an experimental model which will typically be not be suitable for production use and come with more restrictive rate limits. We release experimental models to gather feedback and get our latest updates into the hands of developers quickly.\n\nExperimental models are not stable and availability of model endpoints is subject to change.\n\n## Model deprecations\n\nFor information about model deprecations, visit the Gemini deprecations page."
          },
          {
            "snippetId": "model-details-snippet-2",
            "url": "https://www.youtube.com/watch?v=hf59-PhO3do",
            "snippet": "## AI Papers Slop\n\n##### Nov 18, 2025 (0:15:25)\nTitle: Gemini 3 Pro Model Card\nLink: https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf\nDate: November 2025... Chapters:\n00:00 - Gemini 3 Executive Summary\n01:37 - MoE Architecture Explained\n03:07 - 1 Million Token Capabilities\n03:49 - Synthetic Data and Training\n04:58 - Reasoning and Multimodal Benchmarks\n06:54 - Deep Think Ultra Tier\n08:01 - Vibe Coding Performance\n09:09 - Anti-Gravity Agent Platform\n10:35 - Safety Metrics and Regressions\n11:56 - Frontier Risk Analysis\n13:39 - Availability and Reliability Challenges... ### Transcript\n\n{ts:0} We are jumping straight into it today, analyzing the brand new Gemini 3 Pro\n{ts:4} model card. If you're an engineer, researcher, this is for you. We're going to pull out the high impact essential\n{ts:10} facts you need to know about Google's new flagship model.... And the headline here really isn't just\n{ts:15} an incremental update. This is a a pretty decisive architectural leap, I think, toward what you could call\n{ts:22} egentic AGI. The model card confirms it's a sparse mixture of experts or MOE transformer,\n{ts:28} which is so critical.... It is because it decouples that huge model capacity from the raw computational cost,\n{ts:34} right? And that capacity means real scale you can actually use. We're talking native multimodal text, audio,\n{ts:40} image, video, and a just an enormous 1 million token context window, plus a 64k token output that changes things for... Yes. And they really stress that this is not a fine-tune of 2.5 Pro or any prior\n{ts:105} model. It's a completely new build from the ground up and that new foundation is all about\n{ts:110} this sparse mixture of experts architecture the MOI model right and you know the core idea has... I mean, we're talking about feeding it entire data sets, huge\n{ts:200} complex documents, long audio files, video, and this is the critical part for developers, entire code repository,\n{ts:208} a whole repo, the whole thing. You can give it the full documentation for a complex library... {ts:213} and just ask it to write a patch or explain a dependency. That's a huge shift. that ability to just ingest an\n{ts:220} entire repo without any pre-training or fine-tuning. That's a massive deal for enterprise use. So, okay, how do they\n{ts:227} feed this thing?... Let's talk training data. The card mentions a large scale diverse\n{ts:232} and uh natively multimodal collection. So, you have the usual suspects, public web data, licensed data, and some user\n{ts:240} data with, you know, the standard controls. But there was one thing that really... And the post training using reinforcement learning on stuff like theorem proving data just\n{ts:276} doubles down on that goal. It's all pointing towards agency. And this was all done on Google's own\n{ts:281} hardware. Their TPUs, the tensor processing units, all orchestrated with JX and ML pathways.... The entire platform is designed to let the agent plan and execute complex end to-end\n{ts:566} tasks on its own and critically validate its own work. Critically, it can run tests, check the\n{ts:572} output, see if the UI looks right in the browser. It's a closed loop.... What about the frontier risks? How is Google\n{ts:640} handling safety? They say it's their most secure model yet. They detail all the mitigations,\n{ts:644} data set filtering, RLHF, critic feedback, all the standard stuff. But we need to look closely at the internal\n{ts:650} safety metrics they shared.... {ts:809} challenges. So, it has some foundational planning abilities, but it's not demonstrating dangerous levels of\n{ts:814} self-motivated autonomy in these tests. It's an agent, but it's not a rogue agent.\n{ts:818} So, what does this all mean for developers today?... The capabilities are obviously huge, and the safety analysis,\n{ts:825} while needing a critical eye, seems to clear it for general release. It's rolling out now. Developers can get\n{ts:830} it in AI Studio, Vert.Ex AI, the CLI, and through that new anti-gravity platform."
          },
          {
            "snippetId": "model-details-snippet-3",
            "url": "https://web.archive.org/web/20251118111103if_/https:/storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf",
            "snippet": "Gemini 3 Pro \nModel Card\nGemini 3 Pro - Model Card \n \n \n \nModel Cards are intended to provide essential information on Gemini models, including known \nlimitations, mitigation approaches, and safety performance. Model cards may be updated from \ntime-to-time; for example, to include updated evaluations as the model is improved or revised. See the \nGoogle DeepMind site for a comprehensive list of model cards.... This model card includes more essential information about the Gemini 3 family of models than previous \nmodel cards did. We hope more information about the training dataset, distribution, and intended uses \nwill empower developers with deeper insights and help build more robust and responsible downstream \napplications. \n \nPublished / Model Release: November 2025... Model Information \n \nDescription: Gemini 3 Pro is the next generation in the Gemini series of models, a suite of \nhighly-capable, natively multimodal, reasoning models. Gemini 3 Pro is now Google’s most advanced \nmodel for complex tasks, and can comprehend vast datasets, challenging problems from different \ninformation sources, including text, audio, images, video, and entire code repositories.... data with paired instructions and responses in addition to human preference and tool-use data. Gemini \n3 Pro is trained using reinforcement learning techniques that can leverage multi-step reasoning, \nproblem-solving and theorem-proving data.  \n \nThe training dataset also includes: publicly available datasets that are readily downloadable; data \nobtained by crawlers; licensed data obtained via commercial licensing agreements; user data (i.e., data... collected from users of Google products and services to train AI models, along with user interactions \nwith the model) in accordance with Google’s relevant terms of service, privacy policy, service-specific \npolicies, and pursuant to user controls, where appropriate; other datasets that Google acquires or \ngenerates in the course of its business operations, or directly from its workforce; and AI-generated... growing complexity of large foundation models. Training can be distributed across multiple TPU devices \nfor faster and more efficient processing. \n \nThe efficiencies gained through the use of TPUs are aligned with Google's commitment to operate \nsustainably. \n \nSoftware: Training was done using JAX and ML Pathways. \n \n \n2... Distribution \n \nThe Gemini family of models, including Gemini 3 Pro, are distributed in the following channels; \nrespective documentation shared in line: \n \n●​\nGemini App \n●​\nGoogle Cloud / Vertex AI \n●​\nGoogle AI Studio \n●​\nGemini API \n●​\nGoogle AI Mode \n●​... Google Antigravity \n \nOur models are available to downstream providers via an application program interface (API) and \nsubject to relevant terms of use. There is no required hardware or software to use the model. For \nAI Studio and Gemini API, see the Gemini API Additional Terms of Service; for Vertex AI, see Google \nCloud Platform Terms of Service. For more information, see Gemini Model API instructions and Gemini \nAPI in Vertex AI quickstart.  \n \n \n \n3... applications that require:  agentic performance, advanced coding, long context and/or multimodal \nunderstanding, and/or algorithmic development. \n \nKnown Limitations: Gemini 3 Pro may exhibit some of the general limitations of foundation models, \nsuch as hallucinations. There may also be occasional slowness or timeout issues. The knowledge cutoff... date for Gemini 3 Pro was January 2025.  \n \nAcceptable Usage: Google’s Generative AI Prohibited Use Policy applies to uses of the model in \naccordance with the applicable terms of service. Additionally, the model should not be integrated into \ncertain systems (also found in Google’s Generative AI Prohibited Use Policy), including those that: (1)... Evaluation Approach: Gemini 3 Pro was developed in partnership with internal safety, security, and \nresponsibility teams. A range of evaluations and red teaming activities were conducted to help improve \nthe model and inform decision-making. These evaluations and activities align with Google's AI Principles \nand responsible AI approach, as well as Google's Generative AI policies (e.g. Gen AI Prohibited Use... Policy and the Gemini API Additional Terms of Service).    \n \nEvaluation types included but were not limited to:  \n \n●​\nTraining/Development Evaluations including automated and human evaluations carried out \ncontinuously throughout and after the model’s training, to monitor its progress and \nperformance; \n●​\nHuman Red Teaming conducted by specialist teams who sit outside of the model development... Training and Development Evaluation Results:  Results for some of the internal safety evaluations \nconducted during the development phase are listed below. The evaluation results are for automated \nevaluations and not human evaluation or red teaming. Scores are provided as an absolute percentage \nincrease or decrease in performance compared to the indicated model, as described below. Overall,... Instrumental \nReasoning​\nLevels 1 + 2 \nCCL not \nreached \n \nMore details can be found in the Gemini 3 Pro Frontier Safety Framework Report. \n \n \n \n8"
          },
          {
            "snippetId": "model-details-snippet-4",
            "url": "https://huggingface.co/datasets/multimodalart/google-gemini-3-pro-pre-release-model-card",
            "snippet": "# Gemini 3 Pro Model Card\n\n### ⚠️ This is a mirror to the pre-release model card taht was officially published by Google @ https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf and subsequentially yanked. It will get outdated by the actual release version in a few hours (date of publication Nov 18, 13:16 CET)\n\n*Model card published: November, 2025*... # Gemini 3 Pro - Model Card\n\n*Model Cards* *are intended to provide essential information on Gemini models, including known limitations, mitigation approaches, and safety performance. Model cards may be updated from*\n\n*time-to-time; for example, to include updated evaluations as the model is improved or revised. See the* *Google DeepMind site* *for a comprehensive list of model cards.*... This model card includes more essential information about the Gemini 3 family of models than previous model cards did. We hope more information about the training dataset, distribution, and intended uses will empower developers with deeper insights and help build more robust and responsible downstream applications.\n\n*Published / Model Release: November 2025*... ## Model Information\n\n**Description**: Gemini 3 Pro is the next generation in the Gemini series of models, a suite of\n\nhighly-capable, natively multimodal, reasoning models. Gemini 3 Pro is now Google's most advanced model for complex tasks, and can comprehend vast datasets, challenging problems from diﬀerent information sources, including text, audio, images, video, and entire code repositories.... **Model dependencies:** This model is not a modiﬁcation or a ﬁne-tune of a prior model.\n\n**Inputs:** Text strings (e.g., a question, a prompt, document(s) to be summarized), images, audio, and video ﬁles, with a token context window of up to 1M.... ## Model Data\n\n**Training Dataset:** The pre-training dataset was a large-scale, diverse collection of data encompassing a wide range of domains and modalities, which included publicly-available web-documents, text, code (various programming languages), images, audio (including speech and other audio types) and video.\n\nThe post-training dataset consisted of vetted instruction tuning data and was a collection of multimodal data with paired instructions and responses in addition to human preference and tool-use data. Gemini 3 Pro is trained using reinforcement learning techniques that can leverage multi-step reasoning, problem-solving and theorem-proving data.... The training dataset also includes: publicly available datasets that are readily downloadable; data obtained by crawlers; licensed data obtained via commercial licensing agreements; user data (i.e., data collected from users of Google products and services to train AI models, along with user interactions with the model) in accordance with Google's relevant terms of service, privacy policy, service-speciﬁc policies, and pursuant to user controls, where appropriate; other datasets that Google acquires or generates in the course of its business operations, or directly from its workforce; and AI-generated synthetic data.... The eﬃciencies gained through the use of TPUs are aligned with Google's commitment to operate sustainably.\n\n**Software:** Training was done using JAX and ML Pathways.... ## Distribution\n\nThe Gemini family of models, including Gemini 3 Pro, are distributed in the following channels; respective documentation shared in line:\n\nOur models are available to downstream providers via an application program interface (API) and subject to relevant terms of use. There is no required hardware or software to use the model. For AI Studio and Gemini API, see the Gemini API Additional Terms of Service; for Vertex AI, see Google Cloud Platform Terms of Service. For more information, see Gemini Model API instructions and Gemini API in Vertex AI quickstart.... ## Intended Usage and Limitations\n\n**Beneﬁt and Intended Usage:** Gemini 3 Pro is our most intelligent and adaptive model yet, capable of helping with real-world complexity, solving problems that require enhanced reasoning and intelligence, creativity, strategic planning and making improvements step-by-step. It is particularly well-suited for applications that require: agentic performance, advanced coding, long context and/or multimodal understanding, and/or algorithmic development.... **Known Limitations:** Gemini 3 Pro may exhibit some of the general limitations of foundation models, such as hallucinations. There may also be occasional slowness or timeout issues. The knowledge cutoﬀ date for Gemini 3 Pro was January 2025.... ## Ethics and Content Safety\n\n**Evaluation Approach:** Gemini 3 Pro was developed in partnership with internal safety, security, and responsibility teams. A range of evaluations and red teaming activities were conducted to help improve the model and inform decision-making. These evaluations and activities align with Google's AI Principles and responsible AI approach, as well as Google's Generative AI policies (e.g. Gen AI Prohibited Use Policy and the Gemini API Additional Terms of Service)."
          },
          {
            "snippetId": "model-details-snippet-5",
            "url": "https://www.studocu.com/en-gb/document/university-of-east-london/financial-accounting/gemini-3-pro-model-card-insights-safety-evaluations-nov-2025/146206142",
            "snippet": "Key Concepts\n\n- Multimodal Capabilities: Gemini 3 Pro processes text, images, audio, and video, enhancing its versatility in handling diverse data types.\n\n- Sparse MoE Architecture: This model employs a mixture of experts approach, optimizing computational efficiency by activating only relevant parameters.\n\n- Training Dataset: A comprehensive dataset includes various modalities and is processed to ensure quality and safety.... - Evaluation Methods: The model undergoes rigorous testing across benchmarks to assess its reasoning and multimodal performance.\n\n- Safety Policies: Strict guidelines are in place to prevent harmful content generation, ensuring responsible AI use.\n\n- Intended Applications: Designed for complex problem-solving, the model excels in areas requiring advanced reasoning and creativity.\n\n## Preview text\n\nModel card published: November, 2025... ## Gemini 3 Pro\n\n## Model Card\n\n### Gemini 3 Pro - Model Card\n\nModel Cards are intended to provide essential information on Gemini models, including known limitations, mitigation approaches, and safety performance. Model cards may be updated from time-to-time; for example, to include updated evaluations as the model is improved or revised. See the Google DeepMind site for a comprehensive list of model cards.... This model card includes more essential information about the Gemini 3 family of models than previous model cards did. We hope more information about the training dataset, distribution, and intended uses will empower developers with deeper insights and help build more robust and responsible downstream applications.\n\nPublished / Model Release: November 2025... #### Model Information\n\nDescription: Gemini 3 Pro is the next generation in the Gemini series of models, a suite of highly-capable, natively multimodal, reasoning models. Gemini 3 Pro is now Google’s most advanced model for complex tasks, and can comprehend vast datasets, challenging problems from different information sources, including text, audio, images, video, and entire code repositories.... Model dependencies: This model is not a modification or a fine-tune of a prior model.\n\nInputs: Text strings (e., a question, a prompt, document(s) to be summarized), images, audio, and video files, with a token context window of up to 1M.\n\nOutputs: Text, with a 64K token output.... Architecture: Gemini 3 Pro is a sparse mixture-of-experts (MoE) (Clark et al., 2022; Du et al., 2021; Fedus et al., 2021; Jiang et al., 2024, Lepikhin et al., 2020; Riquelme et al., 2021; Roller et al., 2021; Shazeer et al., 2017 ) transformer-based model (Vaswani et al., 2017) with native multimodal support for text, vision, and audio inputs.... #### Distribution\n\nThe Gemini family of models, including Gemini 3 Pro, are distributed in the following channels; respective documentation shared in line:\n\n● Gemini App ● Google Cloud / Vertex AI ● Google AI Studio ● Gemini API ● Google AI Mode ● Google Antigravity... Our models are available to downstream providers via an application program interface (API) and subject to relevant terms of use. There is no required hardware or software to use the model. For AI Studio and Gemini API, see the Gemini API Additional Terms of Service; for Vertex AI, see Google Cloud Platform Terms of Service. For more information, see Gemini Model API instructions and Gemini API in Vertex AI quickstart.... #### Evaluation\n\nApproach: Gemini 3 Pro was evaluated across a range of benchmarks, including reasoning, multimodal capabilities, agentic tool use, multi-lingual performance, and long-context. Additional benchmarks and details on approach, results and their methodologies can be found at: deepmind/models/evals/gemini-3-pro.... Evaluation 1 Description Gemini 3 Pro vs. Gemini 2 Pro\n\nText to Text Safety Automated content safety evaluation measuring safety policies -10%\n\nMultilingual Safety Automated safety policy evaluation across multiple languages +0% (non-egregious)\n\nImage to Text Safety Automated content safety evaluation measuring safety policies +3% (non-egregious)... Human Red Teaming Results: We conduct manual red teaming by specialist teams who sit outside of the model development team. High-level findings are fed back to the model team. For child safety evaluations, Gemini 3 Pro satisfied required launch thresholds, which were developed by expert teams to protect children online and meet Google’s commitments to child safety across our models and Google products.... ● dataset filtering; ● conditional pre-training; ● supervised fine-tuning; ● reinforcement learning from human and critic feedback; ● safety policies and desiderata; ● product-level mitigations such as safety filtering.\n\nThe main risks for Gemini 3 Pro are: a) jailbreak vulnerability (improved compared to Gemini 2 Pro but still an open research problem), and b) possible degradation in multi-turn conversations."
          }
        ],
        "subsectionChecks": [
          {
            "name": "Model overview",
            "score": 1,
            "explanation": "Gemini 3 Pro is now Google’s most advanced model for complex tasks, and can comprehend vast datasets, challenging problems from different information sources."
          },
          {
            "name": "Organization developing the model",
            "score": 1,
            "explanation": "Gemini 3 Pro was developed in partnership with internal safety, security, and responsibility teams."
          },
          {
            "name": "Model Version",
            "score": 1,
            "explanation": "Model card published: November, 2025"
          },
          {
            "name": "Model Release Date",
            "score": 1,
            "explanation": "Published / Model Release: November 2025"
          },
          {
            "name": "Model Version Progression",
            "score": 1,
            "explanation": "This model is not a modification or a fine-tune of a prior model."
          },
          {
            "name": "Model Architecture",
            "score": 1,
            "explanation": "Gemini 3 Pro is a sparse mixture-of-experts (MoE) transformer-based model."
          },
          {
            "name": "Model Dependencies",
            "score": 1,
            "explanation": "This model is not a modification or a fine-tune of a prior model."
          },
          {
            "name": "Paper and relevant links",
            "score": 1,
            "explanation": "Link: https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf"
          },
          {
            "name": "Model Distribution Forms",
            "score": 1,
            "explanation": "The Gemini family of models, including Gemini 3 Pro, are distributed in the following channels."
          }
        ]
      },
      {
        "sectionId": "model-inputs-outputs",
        "sectionSnippets": [
          {
            "snippetId": "model-inputs-outputs-snippet-1",
            "url": "https://web.archive.org/web/20251118111103if_/https:/storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf",
            "snippet": "Gemini 3 Pro \nModel Card\nGemini 3 Pro - Model Card \n \n \n \nModel Cards are intended to provide essential information on Gemini models, including known \nlimitations, mitigation approaches, and safety performance. Model cards may be updated from \ntime-to-time; for example, to include updated evaluations as the model is improved or revised. See the \nGoogle DeepMind site for a comprehensive list of model cards.... This model card includes more essential information about the Gemini 3 family of models than previous \nmodel cards did. We hope more information about the training dataset, distribution, and intended uses \nwill empower developers with deeper insights and help build more robust and responsible downstream \napplications. \n \nPublished / Model Release: November 2025... Model Information \n \nDescription: Gemini 3 Pro is the next generation in the Gemini series of models, a suite of \nhighly-capable, natively multimodal, reasoning models. Gemini 3 Pro is now Google’s most advanced \nmodel for complex tasks, and can comprehend vast datasets, challenging problems from different \ninformation sources, including text, audio, images, video, and entire code repositories.... Model dependencies: This model is not a modification or a fine-tune of a prior model.   \n \nInputs: Text strings (e.g., a question, a prompt, document(s) to be summarized), images, audio, and \nvideo files, with a token context window of up to 1M.  \n \nOutputs:  Text, with a 64K token output.... data with paired instructions and responses in addition to human preference and tool-use data. Gemini \n3 Pro is trained using reinforcement learning techniques that can leverage multi-step reasoning, \nproblem-solving and theorem-proving data.  \n \nThe training dataset also includes: publicly available datasets that are readily downloadable; data \nobtained by crawlers; licensed data obtained via commercial licensing agreements; user data (i.e., data... specifically designed to handle the massive computations involved in training LLMs and can speed up \ntraining considerably compared to CPUs. TPUs often come with large amounts of high-bandwidth \nmemory, allowing for the handling of large models and batch sizes during training, which can lead to \nbetter model quality. TPU Pods (large clusters of TPUs) also provide a scalable solution for handling the... growing complexity of large foundation models. Training can be distributed across multiple TPU devices \nfor faster and more efficient processing. \n \nThe efficiencies gained through the use of TPUs are aligned with Google's commitment to operate \nsustainably. \n \nSoftware: Training was done using JAX and ML Pathways. \n \n \n2... Distribution \n \nThe Gemini family of models, including Gemini 3 Pro, are distributed in the following channels; \nrespective documentation shared in line: \n \n●​\nGemini App \n●​\nGoogle Cloud / Vertex AI \n●​\nGoogle AI Studio \n●​\nGemini API \n●​\nGoogle AI Mode \n●​... Google Antigravity \n \nOur models are available to downstream providers via an application program interface (API) and \nsubject to relevant terms of use. There is no required hardware or software to use the model. For \nAI Studio and Gemini API, see the Gemini API Additional Terms of Service; for Vertex AI, see Google \nCloud Platform Terms of Service. For more information, see Gemini Model API instructions and Gemini \nAPI in Vertex AI quickstart.  \n \n \n \n3... applications that require:  agentic performance, advanced coding, long context and/or multimodal \nunderstanding, and/or algorithmic development. \n \nKnown Limitations: Gemini 3 Pro may exhibit some of the general limitations of foundation models, \nsuch as hallucinations. There may also be occasional slowness or timeout issues. The knowledge cutoff... Evaluation Approach: Gemini 3 Pro was developed in partnership with internal safety, security, and \nresponsibility teams. A range of evaluations and red teaming activities were conducted to help improve \nthe model and inform decision-making. These evaluations and activities align with Google's AI Principles \nand responsible AI approach, as well as Google's Generative AI policies (e.g. Gen AI Prohibited Use... Policy and the Gemini API Additional Terms of Service).    \n \nEvaluation types included but were not limited to:  \n \n●​\nTraining/Development Evaluations including automated and human evaluations carried out \ncontinuously throughout and after the model’s training, to monitor its progress and \nperformance; \n●​\nHuman Red Teaming conducted by specialist teams who sit outside of the model development... concerns. \n \nRisks and Mitigations: Safety and responsibility was built into Gemini 3 Pro throughout the training and \ndeployment lifecycle, including pre-training, post-training, and product-level mitigations. Mitigations \ninclude, but are not limited to:  \n \n●​\ndataset filtering;  \n●​... Instrumental \nReasoning​\nLevels 1 + 2 \nCCL not \nreached \n \nMore details can be found in the Gemini 3 Pro Frontier Safety Framework Report. \n \n \n \n8"
          },
          {
            "snippetId": "model-inputs-outputs-snippet-2",
            "url": "https://ai.google.dev/gemini-api/docs/tokens",
            "snippet": "## Context windows\n\nThe models available through the Gemini API have context windows that are measured in tokens. The context window defines how much input you can provide and how much output the model can generate. You can determine the size of the context window by calling the getModels endpoint or by looking in the models documentation.\n\nIn the following example, you can see that the... `gemini-1.5-flash` model has an\n\ninput limit of about 1,000,000 tokens and an output limit of about 8,000 tokens,\n\nwhich means a context window is 1,000,000 tokens.\n\n```\n\nfrom google import genai\n\nclient = genai.Client()\n\nmodel_info = client.models.get(model=\"gemini-2.0-flash\")\n\nprint(f\"{model_info.input_token_limit=}\")\n\nprint(f\"{model_info.output_token_limit=}\")\n\n# ( e.g., input_token_limit=30720, output_token_limit=2048 )count_tokens.py\n\n```... ## Count tokens\n\nAll input to and output from the Gemini API is tokenized, including text, image files, and other non-text modalities.\n\nYou can count tokens in the following ways:... # ( e.g., total_tokens: 10 )\n\nresponse = client.models.generate_content(\n\nmodel=\"gemini-2.0-flash\", contents=prompt\n\n\n\n# The usage_metadata provides detailed token counts.\n\nprint(response.usage_metadata)\n\n# ( e.g., prompt_token_count: 11, candidates_token_count: 73, total_token_count: 84 )count_tokens.py\n\n```... ### Count multi-turn (chat) tokens\n\n```\n\nfrom google import genai\n\nfrom google.genai import types\n\nclient = genai.Client()\n\nchat = client.chats.create(\n\nmodel=\"gemini-2.0-flash\",\n\nhistory=[\n\ntypes.Content(\n\nrole=\"user\", parts=[types.Part(text=\"Hi my name is Bob\")]\n\n),\n\ntypes.Content(role=\"model\", parts=[types.Part(text=\"Hi Bob!\")]),... ],\n\n\n\n# Count tokens for the chat history.\n\nprint(\n\nclient.models.count_tokens(\n\nmodel=\"gemini-2.0-flash\", contents=chat.get_history()\n\n\n\n# ( e.g., total_tokens: 10 )\n\nresponse = chat.send_message(\n\nmessage=\"In one sentence, explain how a computer works to a young child.\"... ### Count multimodal tokens\n\nAll input to the Gemini API is tokenized, including text, image files, and other non-text modalities. Note the following high-level key points about tokenization of multimodal input during processing by the Gemini API:\n\nWith Gemini 2.0, image inputs with both dimensions <=384 pixels are counted as 258 tokens. Images larger in one or both dimensions are cropped and scaled as needed into tiles of 768x768 pixels, each counted as 258 tokens. Prior to Gemini 2.0, images used a fixed 258 tokens.... Video and audio files are converted to tokens at the following fixed rates: video at 263 tokens per second and audio at 32 tokens per second.\n\n#### Media resolutions\n\nGemini 3 Pro Preview introduces granular control over multimodal vision processing with the\n\n`media_resolution` parameter. The\n\n`media_resolution` parameter determines the\n\n**maximum number of tokens allocated per input image or video frame.**\n\nHigher resolutions improve the model's ability to\n\nread fine text or identify small details, but increase token usage and latency.\n\nFor more details about the parameter and how it can impact token calculations, see the media resolution guide.... response = client.models.generate_content(\n\nmodel=\"gemini-2.0-flash\", contents=[prompt, your_image_file]\n\n\n\nprint(response.usage_metadata)\n\n# ( e.g., prompt_token_count: 264, candidates_token_count: 80, total_token_count: 345 )count_tokens.py\n\n```... Example that provides the image as inline data:\n\n```\n\nfrom google import genai\n\nimport PIL.Image\n\nclient = genai.Client()\n\nprompt = \"Tell me about this image\"\n\nyour_image_file = PIL.Image.open(media / \"organ.jpg\")\n\n# Count tokens for combined text and inline image.\n\nprint(\n\nclient.models.count_tokens(\n\nmodel=\"gemini-2.0-flash\", contents=[prompt, your_image_file]... # ( e.g., total_tokens: 263 )\n\nresponse = client.models.generate_content(\n\nmodel=\"gemini-2.0-flash\", contents=[prompt, your_image_file]\n\n\n\nprint(response.usage_metadata)\n\n# ( e.g., prompt_token_count: 264, candidates_token_count: 80, total_token_count: 345 )count_tokens.py\n\n```... ### System instructions and tools\n\nSystem instructions and tools also count towards the total token count for the input.\n\nIf you use system instructions, the\n\n`total_tokens` count increases to\n\nreflect the addition of\n\n`system_instruction`.\n\nIf you use function calling, the\n\n`total_tokens` count increases to reflect the\n\naddition of\n\n`tools`."
          },
          {
            "snippetId": "model-inputs-outputs-snippet-3",
            "url": "https://www.youtube.com/watch?v=-XTNBIVXRGA",
            "snippet": "## AI Papers Podcast Daily\n\n##### Nov 20, 2025 (0:13:04)\n\nThe **Gemini 3 Pro Model Card**, published by Google DeepMind in November 2025, introduces the latest generation of the Gemini series, describing it as Google’s most advanced, highly-capable, and natively multimodal reasoning model. Architecturally, Gemini 3 Pro is a sparse Mixture-of-Experts (MoE) transformer-based model, capable of understanding vast datasets and complex problems from various inputs, including text, images, audio, video, and code repositories, utilizing an extensive 1M token context window.... The model was trained using reinforcement learning techniques on a large, diverse dataset, and processed efficiently using Google’s specialized Tensor Processing Units (TPUs). Intended for applications requiring enhanced reasoning, intelligence, advanced coding, and agentic performance, Gemini 3 Pro significantly outperforms the previous Gemini 2.5 Pro model across a range of benchmarks. Development included continuous training evaluations, human red teaming by specialist teams, and adherence to safety policies designed to prevent the generation of harmful content, confirming that Gemini 3 Pro satisfied required launch thresholds for child safety and showed improved overall safety performance compared to its predecessor.... https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf... ### Transcript\n\n{ts:0} Welcome to the AI Papers podcast daily. We have a foundational piece of\n{ts:4} documentation that has just dropped and uh it's really going to set the pace for advanced models over the next year.\n{ts:11} We're going deep on the technical mandate for what Google DeepMind thinks is the new frontier.... {ts:16} That's absolutely right. Our focus today is the brand new Gemini 3 Pro model card just published in November 2025. And\n{ts:25} this is not a small update. This document signals a pretty massive architectural and capability shift.\n{ts:31} Google is calling it their most advanced model for complex tasks.... {ts:113} manage all that input which brings us to scale. I mean and the number that immediately jumps off the\n{ts:117} page is the context window. We're talking about an input of up to 1 million tokens. 1 million.\n{ts:122} Right. And for context a million tokens.... With a million tokens, the model can keep track of details buried anywhere in that\n{ts:146} entire stack of information. But there's an interesting choice here. The input is 1 million tokens, but the\n{ts:152} model card says the text output is limited to 64,000.... And this is where it gets really interesting where we go from just scale to efficiency. The architecture itself.\n{ts:190} The model card specifies Gemini 3 Pro uses a transformer-based sparse mixture of experts or MOI. This\n{ts:198} is a huge concept for anyone building with these models.... {ts:236} So if I ask a programming question, it wakes up the coding expert and maybe the logic expert, but the poetry expert gets\n{ts:243} to stay asleep. Precisely. And that's the core benefit they highlight in the model card. It\n{ts:248} lets Google decouple the model's total capacity, you know, how smart it is in theory, from the actual computation cost... It is. And that efficiency leads to the\n{ts:272} next question. How do you train something this complex? Let's get into the engine room. the training and the\n{ts:277} infrastructure, the pre-training data set is just immense. We're talking web documents, code, images, audio, video.... And you can't talk about training\n{ts:370} without the hardware. This all runs on Google's own silicon. Their tensor processing units, TPUs on scalable TPU\n{ts:378} pods. Yeah, the TPUs are just powerhouses for the kind of math these models need. And\n{ts:383} using their own custom hardware isn't just about speed.... {ts:571} development. If you need a model that can think several steps ahead, this is the tool.\n{ts:575} But even with this huge leap, we have to be realistic. What are the known limitations that the model card flags?\n{ts:582} Well, the usual foundation model issues are still there, primarily hallucinations.... It's not perfect.\n{ts:587} Developers have to build in safeguards. They also note occasional slowness or timeout issues, which probably reflects\n{ts:593} the complexity of the MOI routing. And a really critical point for anyone who needs up-to-date information.\n{ts:599} Yes, the card clearly states the model's knowledge cutoff was January 2025."
          },
          {
            "snippetId": "model-inputs-outputs-snippet-4",
            "url": "https://huggingface.co/datasets/multimodalart/google-gemini-3-pro-pre-release-model-card",
            "snippet": "# Gemini 3 Pro Model Card\n\n### ⚠️ This is a mirror to the pre-release model card taht was officially published by Google @ https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf and subsequentially yanked. It will get outdated by the actual release version in a few hours (date of publication Nov 18, 13:16 CET)\n\n*Model card published: November, 2025*... # Gemini 3 Pro - Model Card\n\n*Model Cards* *are intended to provide essential information on Gemini models, including known limitations, mitigation approaches, and safety performance. Model cards may be updated from*\n\n*time-to-time; for example, to include updated evaluations as the model is improved or revised. See the* *Google DeepMind site* *for a comprehensive list of model cards.*... This model card includes more essential information about the Gemini 3 family of models than previous model cards did. We hope more information about the training dataset, distribution, and intended uses will empower developers with deeper insights and help build more robust and responsible downstream applications.\n\n*Published / Model Release: November 2025*... ## Model Information\n\n**Description**: Gemini 3 Pro is the next generation in the Gemini series of models, a suite of\n\nhighly-capable, natively multimodal, reasoning models. Gemini 3 Pro is now Google's most advanced model for complex tasks, and can comprehend vast datasets, challenging problems from diﬀerent information sources, including text, audio, images, video, and entire code repositories.... **Model dependencies:** This model is not a modiﬁcation or a ﬁne-tune of a prior model.\n\n**Inputs:** Text strings (e.g., a question, a prompt, document(s) to be summarized), images, audio, and video ﬁles, with a token context window of up to 1M.... **Outputs**: Text, with a 64K token output.\n\n**Architecture**: Gemini 3 Pro is a sparse mixture-of-experts (MoE) (Clark et al., 2022; Du et al., 2021; Fedus et al., 2021; Jiang et al., 2024, Lepikhin et al., 2020; Riquelme et al., 2021; Roller et al., 2021; Shazeer et al., 2017) transformer-based model (Vaswani et al., 2017) with native multimodal support for text, vision, and audio inputs.... ## Implementation and Sustainability\n\n**Hardware:** Gemini 3 Pro was trained using Google's Tensor Processing Units (TPUs). TPUs are speciﬁcally designed to handle the massive computations involved in training LLMs and can speed up training considerably compared to CPUs. TPUs often come with large amounts of high-bandwidth memory, allowing for the handling of large models and batch sizes during training, which can lead to better model quality. TPU Pods (large clusters of TPUs) also provide a scalable solution for handling the growing complexity of large foundation models. Training can be distributed across multiple TPU devices for faster and more eﬃcient processing.... The eﬃciencies gained through the use of TPUs are aligned with Google's commitment to operate sustainably.\n\n**Software:** Training was done using JAX and ML Pathways.... ## Distribution\n\nThe Gemini family of models, including Gemini 3 Pro, are distributed in the following channels; respective documentation shared in line:\n\nOur models are available to downstream providers via an application program interface (API) and subject to relevant terms of use. There is no required hardware or software to use the model. For AI Studio and Gemini API, see the Gemini API Additional Terms of Service; for Vertex AI, see Google Cloud Platform Terms of Service. For more information, see Gemini Model API instructions and Gemini API in Vertex AI quickstart.... ## Intended Usage and Limitations\n\n**Beneﬁt and Intended Usage:** Gemini 3 Pro is our most intelligent and adaptive model yet, capable of helping with real-world complexity, solving problems that require enhanced reasoning and intelligence, creativity, strategic planning and making improvements step-by-step. It is particularly well-suited for applications that require: agentic performance, advanced coding, long context and/or multimodal understanding, and/or algorithmic development.... **Training and Development Evaluation Results:** Results for some of the internal safety evaluations conducted during the development phase are listed below. The evaluation results are for automated evaluations and not human evaluation or red teaming. Scores are provided as an absolute percentage increase or decrease in performance compared to the indicated model, as described below. Overall, Gemini 3 Pro outperforms Gemini 2.5 Pro across both safety and tone, while keeping unjustiﬁed refusals low. We mark improvements in green and regressions in red."
          },
          {
            "snippetId": "model-inputs-outputs-snippet-5",
            "url": "https://ai.google.dev/gemini-api/docs/changelog",
            "snippet": "This page documents updates to the Gemini API.\n\n## November 20, 2025\n\n- Released Gemini 3 Pro Image Preview,\n\n`gemini-3-pro-image-preview`, the next iteration to the Nano Banana model. Read the Image generation page for more details.... ## November 18, 2025\n\nLaunched the first Gemini 3 series model,\n\n`gemini-3-pro-preview`, our state-of-the-art reasoning and multimodal understanding model with powerful agentic and coding capabilities.\n\nIn addition to improvements in intelligence and performance, Gemini 3 Pro Preview introduces new behavior around:\n\nRead the Gemini 3 Developer Guide for migration, new features, and specs.... ## October 29, 2025\n\n- Launched the new logging and datasets tool for the Gemini API.... ## September 25, 2025\n\nReleased Gemini Robotics-ER 1.5 model in preview. See the Robotics overview to learn about how to use the model for your robotics application.\n\nLaunched following preview models:\n\n`gemini-2.5-flash-preview-09-2025`\n\n`gemini-2.5-flash-lite-preview-09-2025`\n\nSee the Models page for details.... **Model updates:**\n\n- Released\n\n`gemini-2.5-flash-preview-05-20`, a Gemini preview model optimized for price-performance and adaptive thinking. To learn more, see Gemini 2.5 Flash Preview and Thinking.\n\n- Released the\n\n`gemini-2.5-pro-preview-tts`and... `speechConfig`.\n\n**Text Streaming:**Receive text responses incrementally as they are generated, enabling faster display to the user. **Token Usage Reporting:**Gain insights into usage with detailed token counts provided in the\n\n`usageMetadata`field of server messages, broken down by modality and prompt or response phases.\n\n\n\n## April 4, 2025\n\n- Released\n\n`gemini-2.5-pro-preview-03-25`, a public preview Gemini 2.5 Pro version with billing enabled. You can continue to use\n\n`gemini-2.5-pro-exp-03-25`on the free tier.... ## March 12, 2025\n\n**Model updates:**\n\n- Launched an experimental Gemini 2.0 Flash model capable of image generation and editing.\n\n- Released\n\n`gemma-3-27b-it`, available on AI Studio and through the Gemini API, as part of the Gemma 3 launch.\n\n**API updates:**\n\n- Added support for YouTube URLs as a media source.\n\n- Added support for including an inline video of less than 20MB.... ## February 11, 2025\n\n**API updates:**\n\n- Updates on the OpenAI libraries compatibility.\n\n## February 6, 2025\n\n**Model updates:**\n\n- Released\n\n`imagen-3.0-generate-002`, a generally available (GA) version of Imagen 3 in the Gemini API.\n\n**SDK updates:**\n\n- Released the Google Gen AI SDK for Java for public preview.... ## October 3, 2024\n\n**Model updates:**\n\n- Released\n\n`gemini-1.5-flash-8b-001`, a stable version of our smallest Gemini API model.... ## September 24, 2024\n\n**Model updates:**\n\n- Released\n\n`gemini-1.5-pro-002`and\n\n`gemini-1.5-flash-002`, two new stable versions of Gemini 1.5 Pro and 1.5 Flash, for general availability.... - Updated the\n\n`gemini-1.5-pro-latest`model code to use\n\n`gemini-1.5-pro-002`and the\n\n`gemini-1.5-flash-latest`model code to use\n\n`gemini-1.5-flash-002`.\n\n- Released... ## August 27, 2024\n\n**Model updates:**\n\n- Released the following\n\nexperimental models:\n\n`gemini-1.5-pro-exp-0827`\n\n`gemini-1.5-flash-exp-0827`\n\n`gemini-1.5-flash-8b-exp-0827`... ## May 10, 2024\n\n**Model updates:**\n\n- Released Gemini 1.5 Flash\n\n\n\n`gemini-1.5-flash-latest`) in preview.... ## March 19, 2024\n\n**Model updates:**\n\n- Added support for tuning Gemini 1.0 Pro in Google AI Studio or with the Gemini API.... - Streaming available through the\n\n`StreamGenerateContent`method.\n\n- Multimodal capability: Image is a new supported modality\n\n- New beta features:\n\n- Function Calling\n\n- Semantic Retriever\n\n- Attributed Question Answering (AQA)\n\n- Updated candidate count: Gemini models only return 1 candidate.\n\n- Different Safety Settings and SafetyRating categories. See safety settings for more details.\n\n- Tuning models is not yet supported for Gemini models (Work in progress)."
          }
        ],
        "subsectionChecks": [
          {
            "name": "Inputs",
            "score": 1,
            "explanation": "Text strings (e.g., a question, a prompt, document(s) to be summarized), images, audio, and video files, with a token context window of up to 1M."
          },
          {
            "name": "Outputs",
            "score": 1,
            "explanation": "Text, with a 64K token output."
          },
          {
            "name": "Token Count",
            "score": 1,
            "explanation": "The context window defines how much input you can provide and how much output the model can generate."
          }
        ]
      },
      {
        "sectionId": "model-data",
        "sectionSnippets": [
          {
            "snippetId": "model-data-snippet-1",
            "url": "https://web.archive.org/web/20251118111103if_/https:/storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf",
            "snippet": "Gemini 3 Pro \nModel Card\nGemini 3 Pro - Model Card \n \n \n \nModel Cards are intended to provide essential information on Gemini models, including known \nlimitations, mitigation approaches, and safety performance. Model cards may be updated from \ntime-to-time; for example, to include updated evaluations as the model is improved or revised. See the \nGoogle DeepMind site for a comprehensive list of model cards.... This model card includes more essential information about the Gemini 3 family of models than previous \nmodel cards did. We hope more information about the training dataset, distribution, and intended uses \nwill empower developers with deeper insights and help build more robust and responsible downstream \napplications. \n \nPublished / Model Release: November 2025... Model Information \n \nDescription: Gemini 3 Pro is the next generation in the Gemini series of models, a suite of \nhighly-capable, natively multimodal, reasoning models. Gemini 3 Pro is now Google’s most advanced \nmodel for complex tasks, and can comprehend vast datasets, challenging problems from different \ninformation sources, including text, audio, images, video, and entire code repositories.... Model Data \n \nTraining Dataset: The pre-training dataset was a large-scale, diverse collection of data encompassing a \nwide range of domains and modalities, which included publicly-available web-documents, text, code \n(various programming languages), images, audio (including speech and other audio types) and video. \nThe post-training dataset consisted of vetted instruction tuning data and was a collection of multimodal... data with paired instructions and responses in addition to human preference and tool-use data. Gemini \n3 Pro is trained using reinforcement learning techniques that can leverage multi-step reasoning, \nproblem-solving and theorem-proving data.  \n \nThe training dataset also includes: publicly available datasets that are readily downloadable; data \nobtained by crawlers; licensed data obtained via commercial licensing agreements; user data (i.e., data... collected from users of Google products and services to train AI models, along with user interactions \nwith the model) in accordance with Google’s relevant terms of service, privacy policy, service-specific \npolicies, and pursuant to user controls, where appropriate; other datasets that Google acquires or \ngenerates in the course of its business operations, or directly from its workforce; and AI-generated... synthetic data.   \n \nTraining Data Processing: Data filtering and preprocessing included techniques such as deduplication, \nhonoring robots.txt, safety filtering in-line with Google's commitment to advancing AI safely and \nresponsibly, and quality filtering to mitigate risks and improve training data reliability. Once data is \ncollected, it is cleaned and preprocessed to make it suitable for training. This process involves, on a... growing complexity of large foundation models. Training can be distributed across multiple TPU devices \nfor faster and more efficient processing. \n \nThe efficiencies gained through the use of TPUs are aligned with Google's commitment to operate \nsustainably. \n \nSoftware: Training was done using JAX and ML Pathways. \n \n \n2... Distribution \n \nThe Gemini family of models, including Gemini 3 Pro, are distributed in the following channels; \nrespective documentation shared in line: \n \n●​\nGemini App \n●​\nGoogle Cloud / Vertex AI \n●​\nGoogle AI Studio \n●​\nGemini API \n●​\nGoogle AI Mode \n●​... Intended Usage and Limitations \n \nBenefit and Intended Usage: Gemini 3 Pro is our most intelligent and adaptive model yet, capable of \nhelping with real-world complexity, solving problems that require enhanced reasoning and intelligence, \ncreativity, strategic planning and making improvements step-by-step. It is particularly well-suited for... Evaluation Approach: Gemini 3 Pro was developed in partnership with internal safety, security, and \nresponsibility teams. A range of evaluations and red teaming activities were conducted to help improve \nthe model and inform decision-making. These evaluations and activities align with Google's AI Principles \nand responsible AI approach, as well as Google's Generative AI policies (e.g. Gen AI Prohibited Use... Policy and the Gemini API Additional Terms of Service).    \n \nEvaluation types included but were not limited to:  \n \n●​\nTraining/Development Evaluations including automated and human evaluations carried out \ncontinuously throughout and after the model’s training, to monitor its progress and \nperformance; \n●​\nHuman Red Teaming conducted by specialist teams who sit outside of the model development... Training and Development Evaluation Results:  Results for some of the internal safety evaluations \nconducted during the development phase are listed below. The evaluation results are for automated \nevaluations and not human evaluation or red teaming. Scores are provided as an absolute percentage \nincrease or decrease in performance compared to the indicated model, as described below. Overall,... concerns. \n \nRisks and Mitigations: Safety and responsibility was built into Gemini 3 Pro throughout the training and \ndeployment lifecycle, including pre-training, post-training, and product-level mitigations. Mitigations \ninclude, but are not limited to:  \n \n●​\ndataset filtering;  \n●​"
          },
          {
            "snippetId": "model-data-snippet-2",
            "url": "https://huggingface.co/datasets/multimodalart/google-gemini-3-pro-pre-release-model-card",
            "snippet": "# Gemini 3 Pro - Model Card\n\n*Model Cards* *are intended to provide essential information on Gemini models, including known limitations, mitigation approaches, and safety performance. Model cards may be updated from*\n\n*time-to-time; for example, to include updated evaluations as the model is improved or revised. See the* *Google DeepMind site* *for a comprehensive list of model cards.*... This model card includes more essential information about the Gemini 3 family of models than previous model cards did. We hope more information about the training dataset, distribution, and intended uses will empower developers with deeper insights and help build more robust and responsible downstream applications.\n\n*Published / Model Release: November 2025*... ## Model Information\n\n**Description**: Gemini 3 Pro is the next generation in the Gemini series of models, a suite of\n\nhighly-capable, natively multimodal, reasoning models. Gemini 3 Pro is now Google's most advanced model for complex tasks, and can comprehend vast datasets, challenging problems from diﬀerent information sources, including text, audio, images, video, and entire code repositories.... **Model dependencies:** This model is not a modiﬁcation or a ﬁne-tune of a prior model.\n\n**Inputs:** Text strings (e.g., a question, a prompt, document(s) to be summarized), images, audio, and video ﬁles, with a token context window of up to 1M.... ## Model Data\n\n**Training Dataset:** The pre-training dataset was a large-scale, diverse collection of data encompassing a wide range of domains and modalities, which included publicly-available web-documents, text, code (various programming languages), images, audio (including speech and other audio types) and video.\n\nThe post-training dataset consisted of vetted instruction tuning data and was a collection of multimodal data with paired instructions and responses in addition to human preference and tool-use data. Gemini 3 Pro is trained using reinforcement learning techniques that can leverage multi-step reasoning, problem-solving and theorem-proving data.... The training dataset also includes: publicly available datasets that are readily downloadable; data obtained by crawlers; licensed data obtained via commercial licensing agreements; user data (i.e., data collected from users of Google products and services to train AI models, along with user interactions with the model) in accordance with Google's relevant terms of service, privacy policy, service-speciﬁc policies, and pursuant to user controls, where appropriate; other datasets that Google acquires or generates in the course of its business operations, or directly from its workforce; and AI-generated synthetic data.... **Training Data Processing:** Data ﬁltering and preprocessing included techniques such as deduplication, honoring robots.txt, safety ﬁltering in-line with Google's commitment to advancing AI safely and responsibly, and quality ﬁltering to mitigate risks and improve training data reliability. Once data is collected, it is cleaned and preprocessed to make it suitable for training. This process involves, on a\n\ncase-by-case basis, ﬁltering irrelevant or harmful content, text, and other modalities, including ﬁltering content that is pornographic, violent, or violative of child sexual abuse material (CSAM) laws.... ## Implementation and Sustainability\n\n**Hardware:** Gemini 3 Pro was trained using Google's Tensor Processing Units (TPUs). TPUs are speciﬁcally designed to handle the massive computations involved in training LLMs and can speed up training considerably compared to CPUs. TPUs often come with large amounts of high-bandwidth memory, allowing for the handling of large models and batch sizes during training, which can lead to better model quality. TPU Pods (large clusters of TPUs) also provide a scalable solution for handling the growing complexity of large foundation models. Training can be distributed across multiple TPU devices for faster and more eﬃcient processing.... The eﬃciencies gained through the use of TPUs are aligned with Google's commitment to operate sustainably.\n\n**Software:** Training was done using JAX and ML Pathways.... ## Distribution\n\nThe Gemini family of models, including Gemini 3 Pro, are distributed in the following channels; respective documentation shared in line:\n\nOur models are available to downstream providers via an application program interface (API) and subject to relevant terms of use. There is no required hardware or software to use the model. For AI Studio and Gemini API, see the Gemini API Additional Terms of Service; for Vertex AI, see Google Cloud Platform Terms of Service. For more information, see Gemini Model API instructions and Gemini API in Vertex AI quickstart.... ## Intended Usage and Limitations\n\n**Beneﬁt and Intended Usage:** Gemini 3 Pro is our most intelligent and adaptive model yet, capable of helping with real-world complexity, solving problems that require enhanced reasoning and intelligence, creativity, strategic planning and making improvements step-by-step. It is particularly well-suited for applications that require: agentic performance, advanced coding, long context and/or multimodal understanding, and/or algorithmic development."
          },
          {
            "snippetId": "model-data-snippet-3",
            "url": "https://www.studocu.com/en-gb/document/university-of-east-london/financial-accounting/gemini-3-pro-model-card-insights-safety-evaluations-nov-2025/146206142",
            "snippet": "Key Concepts\n\n- Multimodal Capabilities: Gemini 3 Pro processes text, images, audio, and video, enhancing its versatility in handling diverse data types.\n\n- Sparse MoE Architecture: This model employs a mixture of experts approach, optimizing computational efficiency by activating only relevant parameters.\n\n- Training Dataset: A comprehensive dataset includes various modalities and is processed to ensure quality and safety.... - Evaluation Methods: The model undergoes rigorous testing across benchmarks to assess its reasoning and multimodal performance.\n\n- Safety Policies: Strict guidelines are in place to prevent harmful content generation, ensuring responsible AI use.\n\n- Intended Applications: Designed for complex problem-solving, the model excels in areas requiring advanced reasoning and creativity.\n\n## Preview text\n\nModel card published: November, 2025... ## Gemini 3 Pro\n\n## Model Card\n\n### Gemini 3 Pro - Model Card\n\nModel Cards are intended to provide essential information on Gemini models, including known limitations, mitigation approaches, and safety performance. Model cards may be updated from time-to-time; for example, to include updated evaluations as the model is improved or revised. See the Google DeepMind site for a comprehensive list of model cards.... This model card includes more essential information about the Gemini 3 family of models than previous model cards did. We hope more information about the training dataset, distribution, and intended uses will empower developers with deeper insights and help build more robust and responsible downstream applications.\n\nPublished / Model Release: November 2025... #### Model Information\n\nDescription: Gemini 3 Pro is the next generation in the Gemini series of models, a suite of highly-capable, natively multimodal, reasoning models. Gemini 3 Pro is now Google’s most advanced model for complex tasks, and can comprehend vast datasets, challenging problems from different information sources, including text, audio, images, video, and entire code repositories.... Model dependencies: This model is not a modification or a fine-tune of a prior model.\n\nInputs: Text strings (e., a question, a prompt, document(s) to be summarized), images, audio, and video files, with a token context window of up to 1M.\n\nOutputs: Text, with a 64K token output.... Architecture: Gemini 3 Pro is a sparse mixture-of-experts (MoE) (Clark et al., 2022; Du et al., 2021; Fedus et al., 2021; Jiang et al., 2024, Lepikhin et al., 2020; Riquelme et al., 2021; Roller et al., 2021; Shazeer et al., 2017 ) transformer-based model (Vaswani et al., 2017) with native multimodal support for text, vision, and audio inputs.... #### Distribution\n\nThe Gemini family of models, including Gemini 3 Pro, are distributed in the following channels; respective documentation shared in line:\n\n● Gemini App ● Google Cloud / Vertex AI ● Google AI Studio ● Gemini API ● Google AI Mode ● Google Antigravity... Our models are available to downstream providers via an application program interface (API) and subject to relevant terms of use. There is no required hardware or software to use the model. For AI Studio and Gemini API, see the Gemini API Additional Terms of Service; for Vertex AI, see Google Cloud Platform Terms of Service. For more information, see Gemini Model API instructions and Gemini API in Vertex AI quickstart.... #### Evaluation\n\nApproach: Gemini 3 Pro was evaluated across a range of benchmarks, including reasoning, multimodal capabilities, agentic tool use, multi-lingual performance, and long-context. Additional benchmarks and details on approach, results and their methodologies can be found at: deepmind/models/evals/gemini-3-pro.... Training and Development Evaluation Results: Results for some of the internal safety evaluations conducted during the development phase are listed below. The evaluation results are for automated evaluations and not human evaluation or red teaming. Scores are provided as an absolute percentage increase or decrease in performance compared to the indicated model, as described below. Overall, Gemini 3 Pro outperforms Gemini 2 Pro across both safety and tone, while keeping unjustified refusals low. We mark improvements in green and regressions in red.... Human Red Teaming Results: We conduct manual red teaming by specialist teams who sit outside of the model development team. High-level findings are fed back to the model team. For child safety evaluations, Gemini 3 Pro satisfied required launch thresholds, which were developed by expert teams to protect children online and meet Google’s commitments to child safety across our models and Google products.... ● dataset filtering; ● conditional pre-training; ● supervised fine-tuning; ● reinforcement learning from human and critic feedback; ● safety policies and desiderata; ● product-level mitigations such as safety filtering.\n\nThe main risks for Gemini 3 Pro are: a) jailbreak vulnerability (improved compared to Gemini 2 Pro but still an open research problem), and b) possible degradation in multi-turn conversations."
          },
          {
            "snippetId": "model-data-snippet-4",
            "url": "https://ai.google.dev/gemini-api/docs/changelog",
            "snippet": "This page documents updates to the Gemini API.\n\n## November 20, 2025\n\n- Released Gemini 3 Pro Image Preview,\n\n`gemini-3-pro-image-preview`, the next iteration to the Nano Banana model. Read the Image generation page for more details.... ## November 18, 2025\n\nLaunched the first Gemini 3 series model,\n\n`gemini-3-pro-preview`, our state-of-the-art reasoning and multimodal understanding model with powerful agentic and coding capabilities.\n\nIn addition to improvements in intelligence and performance, Gemini 3 Pro Preview introduces new behavior around:\n\nRead the Gemini 3 Developer Guide for migration, new features, and specs.... ## November 10, 2025\n\nThe following model is deprecated:\n\n`imagen-3.0-generate-002`\n\nUse Imagen 4 instead. Refer to the Gemini deprecations table for more details.\n\n\n\n## November 6, 2025\n\n- Launched the File Search API to public preview, enabling developers to ground responses in their own data. Read the new File Search page for more info.... ## October 29, 2025\n\n- Launched the new logging and datasets tool for the Gemini API.... ## September 25, 2025\n\nReleased Gemini Robotics-ER 1.5 model in preview. See the Robotics overview to learn about how to use the model for your robotics application.\n\nLaunched following preview models:\n\n`gemini-2.5-flash-preview-09-2025`\n\n`gemini-2.5-flash-lite-preview-09-2025`\n\nSee the Models page for details.... ## June 24, 2025\n\n- Released Imagen 4 Ultra and Standard Preview models. To learn more, see the Image generation page.... ## June 17, 2025\n\n- Released\n\n`gemini-2.5-pro`, the stable version of our most powerful model, now with adaptive thinking. To learn more, see Gemini 2.5 Pro and Thinking.\n\n`gemini-2.5-pro-preview-05-06`will be redirected to... ## June 05, 2025\n\n- Released\n\n`gemini-2.5-pro-preview-06-05`, a new version of our most powerful model, now with adaptive thinking. To learn more, see Gemini 2.5 Pro Preview and Thinking.\n\n`gemini-2.5-pro-preview-05-06`will be redirected to\n\n`gemini-2.5-pro`on June 26, 2025.... **Model updates:**\n\n- Released\n\n`gemini-2.5-flash-preview-05-20`, a Gemini preview model optimized for price-performance and adaptive thinking. To learn more, see Gemini 2.5 Flash Preview and Thinking.\n\n- Released the\n\n`gemini-2.5-pro-preview-tts`and... ## May 7, 2025\n\n- Released\n\n`gemini-2.0-flash-preview-image-generation`, a preview model for generating and editing images. To learn more, see Image generation and Gemini 2.0 Flash Preview Image Generation.\n\n## May 6, 2025\n\n- Released\n\n`gemini-2.5-pro-preview-05-06`, a new version of our most powerful model, with improvements on code and function calling.\n\n`gemini-2.5-pro-preview-03-25`will automatically point to the new version of the model.... ## February 11, 2025\n\n**API updates:**\n\n- Updates on the OpenAI libraries compatibility.\n\n## February 6, 2025\n\n**Model updates:**\n\n- Released\n\n`imagen-3.0-generate-002`, a generally available (GA) version of Imagen 3 in the Gemini API.\n\n**SDK updates:**\n\n- Released the Google Gen AI SDK for Java for public preview.... ## March 19, 2024\n\n**Model updates:**\n\n- Added support for tuning Gemini 1.0 Pro in Google AI Studio or with the Gemini API.... ## December 13 2023\n\n**Model updates:**\n\n- gemini-pro: New text model for a wide variety of tasks. Balances capability and efficiency.\n\n- gemini-pro-vision: New multimodal model for a wide variety of tasks. Balances capability and efficiency.\n\n- embedding-001: New embeddings model.\n\n- aqa: A new specially tuned model that is trained to answer questions using text passages for grounding generated answers.... - Streaming available through the\n\n`StreamGenerateContent`method.\n\n- Multimodal capability: Image is a new supported modality\n\n- New beta features:\n\n- Function Calling\n\n- Semantic Retriever\n\n- Attributed Question Answering (AQA)\n\n- Updated candidate count: Gemini models only return 1 candidate.\n\n- Different Safety Settings and SafetyRating categories. See safety settings for more details.\n\n- Tuning models is not yet supported for Gemini models (Work in progress)."
          },
          {
            "snippetId": "model-data-snippet-5",
            "url": "https://en.wikipedia.org/wiki/Gemini_(language_model)",
            "snippet": "**Gemini** is a family of multimodal large language models (LLMs) developed by Google DeepMind, and the successor to LaMDA and PaLM 2. Comprising Gemini Pro, Gemini Flash, and Gemini Lite, it was announced on December 6, 2023. It powers the chatbot of the same name.... At launch, Gemini Pro and Nano were integrated into Bard and the Pixel 8 Pro smartphone, respectively, while Gemini Ultra was set to power \"Bard Advanced\" and become available to software developers in early 2024. Other products that Google intended to incorporate Gemini into included Search, Ads, Chrome, Duet AI on Google Workspace, and AlphaCode 2.... It was made available only in English. Touted as Google's \"largest and most capable AI model\" and designed to emulate human behavior, the company stated that Gemini would not be made widely available until the following year due to the need for \"extensive safety testing\". Gemini was trained on and powered by Google's Tensor Processing Units (TPUs), and the name is in reference to the DeepMind–Google Brain merger as well as NASA's Project Gemini.... Gemini Ultra was also the first language model to outperform human experts on the 57-subject Massive Multitask Language Understanding (MMLU) test, obtaining a score of 90%. Gemini Pro was made available to Google Cloud customers on AI Studio and Vertex AI on December 13, while Gemini Nano will be made available to Android developers as well.... It also introduces improved agentic capabilities, a new Google Gen AI SDK, and \"Jules,\" an experimental AI coding agent for GitHub. Additionally, Google Colab is integrating Gemini 2.0 to generate data science notebooks from natural language. Gemini 2.0 was available through the Gemini chat interface for all users as \"Gemini 2.0 Flash experimental\".... On January 30, 2025, Google released Gemini 2.0 Flash as the new default model, with Gemini 1.5 Flash still available for usage. This was followed by the release of Gemini 2.0 Pro on February 5, 2025. Additionally, Google released Gemini 2.0 Flash Thinking Experimental, which details the language model's thinking process when responding to prompts.... On March 12, 2025, Google also announced Gemini Robotics, a vision-language-action model based on the Gemini 2.0 family of models.\n\nThe next day, Google announced that Gemini in Android Studio would be able to understand simple UI mockups and transform them into working Jetpack Compose code.... Gemini 2.5 Pro Experimental was released on March 25, 2025, described by Google as its most intelligent AI model yet, featuring enhanced reasoning and coding capabilities, and a \"thinking model\" capable of reasoning through steps before responding, using techniques like chain-of-thought prompting, whilst maintaining native multimodality and launching with a 1 million token context window.... At Google I/O 2025, Google announced significant updates to its Gemini core models. Gemini 2.5 Flash became the default model, delivering faster responses. Gemini 2.5 Pro was introduced as the most advanced Gemini model, featuring reasoning, coding capabilities, and the new Deep Think mode for complex tasks. Both 2.5 Pro and Flash support native audio output and improved security.... On June 17, 2025, Google announced general availability for 2.5 Pro and Flash. They also introduced Gemini 2.5 Flash-Lite that same day, a model optimized for speed and cost-efficiency.... On November 18th, 2025, Google announced the release of 3.0 Pro and 3.0 Deep Think. These new models replace 2.5 Pro and Flash, and are the most powerful models available as of November 2025. On release 3.0 Pro outperformed major AI models in 19 out of 20 benchmarks tested, including surpassing OpenAI's GPT-5 Pro in Humanity's Last Exam, with an accuracy of 41% compared to OpenAI's 31.64%.... |3.0 Pro Image (Nano Banana Pro)|20 November 2025|Active|An improved version of Nano Banana which includes better text rendering and better real world knowledge.|... Gemini and Gemma models are decoder-only transformers, with modifications to allow efficient training and inference on TPUs. The 1.0 generation uses multi-query attention.\n\n**Technical specifications of Gemini models**... ## External links\n- Official website\n- Press release via *The Keyword*\n- White paper for 1.0 and 1.5\n- White paper for Gemini 3.0 Pro [1]\n\nCategories: - 2023 software\n- Chatbots\n- Google DeepMind\n- Google software\n- Large language models\n- Multimodal interaction\n- 2023 in artificial intelligence\n- Generative pre-trained transformers"
          }
        ],
        "subsectionChecks": [
          {
            "name": "Training Dataset",
            "score": 1,
            "explanation": "The pre-training dataset was a large-scale, diverse collection of data encompassing a wide range of domains and modalities."
          },
          {
            "name": "Training Data Processing",
            "score": 1,
            "explanation": "Data filtering and preprocessing included techniques such as deduplication, honoring robots.txt, safety filtering in-line with Google's commitment to advancing AI safely and responsibly."
          },
          {
            "name": "Knowledge Count",
            "score": 0,
            "explanation": "did not mention this idea"
          }
        ]
      },
      {
        "sectionId": "model-implementation-sustainability",
        "sectionSnippets": [
          {
            "snippetId": "model-implementation-sustainability-snippet-1",
            "url": "https://web.archive.org/web/20251118111103if_/https:/storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf",
            "snippet": "Gemini 3 Pro \nModel Card\nGemini 3 Pro - Model Card \n \n \n \nModel Cards are intended to provide essential information on Gemini models, including known \nlimitations, mitigation approaches, and safety performance. Model cards may be updated from \ntime-to-time; for example, to include updated evaluations as the model is improved or revised. See the \nGoogle DeepMind site for a comprehensive list of model cards.... This model card includes more essential information about the Gemini 3 family of models than previous \nmodel cards did. We hope more information about the training dataset, distribution, and intended uses \nwill empower developers with deeper insights and help build more robust and responsible downstream \napplications. \n \nPublished / Model Release: November 2025... data with paired instructions and responses in addition to human preference and tool-use data. Gemini \n3 Pro is trained using reinforcement learning techniques that can leverage multi-step reasoning, \nproblem-solving and theorem-proving data.  \n \nThe training dataset also includes: publicly available datasets that are readily downloadable; data \nobtained by crawlers; licensed data obtained via commercial licensing agreements; user data (i.e., data... synthetic data.   \n \nTraining Data Processing: Data filtering and preprocessing included techniques such as deduplication, \nhonoring robots.txt, safety filtering in-line with Google's commitment to advancing AI safely and \nresponsibly, and quality filtering to mitigate risks and improve training data reliability. Once data is \ncollected, it is cleaned and preprocessed to make it suitable for training. This process involves, on a... growing complexity of large foundation models. Training can be distributed across multiple TPU devices \nfor faster and more efficient processing. \n \nThe efficiencies gained through the use of TPUs are aligned with Google's commitment to operate \nsustainably. \n \nSoftware: Training was done using JAX and ML Pathways. \n \n \n2... Distribution \n \nThe Gemini family of models, including Gemini 3 Pro, are distributed in the following channels; \nrespective documentation shared in line: \n \n●​\nGemini App \n●​\nGoogle Cloud / Vertex AI \n●​\nGoogle AI Studio \n●​\nGemini API \n●​\nGoogle AI Mode \n●​... Google Antigravity \n \nOur models are available to downstream providers via an application program interface (API) and \nsubject to relevant terms of use. There is no required hardware or software to use the model. For \nAI Studio and Gemini API, see the Gemini API Additional Terms of Service; for Vertex AI, see Google \nCloud Platform Terms of Service. For more information, see Gemini Model API instructions and Gemini \nAPI in Vertex AI quickstart.  \n \n \n \n3... Intended Usage and Limitations \n \nBenefit and Intended Usage: Gemini 3 Pro is our most intelligent and adaptive model yet, capable of \nhelping with real-world complexity, solving problems that require enhanced reasoning and intelligence, \ncreativity, strategic planning and making improvements step-by-step. It is particularly well-suited for... Evaluation Approach: Gemini 3 Pro was developed in partnership with internal safety, security, and \nresponsibility teams. A range of evaluations and red teaming activities were conducted to help improve \nthe model and inform decision-making. These evaluations and activities align with Google's AI Principles \nand responsible AI approach, as well as Google's Generative AI policies (e.g. Gen AI Prohibited Use... Policy and the Gemini API Additional Terms of Service).    \n \nEvaluation types included but were not limited to:  \n \n●​\nTraining/Development Evaluations including automated and human evaluations carried out \ncontinuously throughout and after the model’s training, to monitor its progress and \nperformance; \n●​\nHuman Red Teaming conducted by specialist teams who sit outside of the model development... team, across the policies and desiderata, deliberately trying to spot weaknesses and ensure the \nmodel adheres to safety policies and desired outcomes;  \n●​\nAutomated Red Teaming to dynamically evaluate Gemini for safety and security \nconsiderations at scale, complementing human red teaming and static evaluations; \n●​\nEthics & Safety Reviews were conducted ahead of the model’s release... Training and Development Evaluation Results:  Results for some of the internal safety evaluations \nconducted during the development phase are listed below. The evaluation results are for automated \nevaluations and not human evaluation or red teaming. Scores are provided as an absolute percentage \nincrease or decrease in performance compared to the indicated model, as described below. Overall,... standard of results. The performance results reported below are computed with improved evaluations \nand thus are not directly comparable with performance results found in previous Gemini model cards. \n \nWe expect variation in our automated safety evaluations results, which is why we review flagged content \nto check for egregious or dangerous material. Our manual review confirmed losses were... concerns. \n \nRisks and Mitigations: Safety and responsibility was built into Gemini 3 Pro throughout the training and \ndeployment lifecycle, including pre-training, post-training, and product-level mitigations. Mitigations \ninclude, but are not limited to:  \n \n●​\ndataset filtering;  \n●​"
          },
          {
            "snippetId": "model-implementation-sustainability-snippet-2",
            "url": "https://ai.google.dev/gemini-api/docs/models",
            "snippet": "OUR MOST INTELLIGENT MODEL\n\n## Gemini 3 Pro\n\nThe best model in the world for multimodal understanding, and our most powerful agentic and vibe-coding model yet, delivering richer visuals and deeper interactivity, all built on a foundation of state-of-the-art reasoning.\n\n### Expand to learn more\n\n#### Model details... ### Gemini 3 Pro Preview\n\n|Property|Description|\n|--|--|\n|Model code|`gemini-3-pro-preview`|\n|Supported data types|Text, Image, Video, Audio, and PDF Text|\n|Token limits [*]|1,048,576 65,536|\n|Capabilities|Not supported Supported Supported Supported Supported Supported Not supported Not supported Not supported Supported Supported Supported Supported|\n|Versions||\n|Latest update|November 2025|\n|Knowledge cutoff|January 2025|... ### Gemini 3 Pro Image Preview\n\n|Property|Description|\n|--|--|\n|Model code|`gemini-3-pro-image-preview`|\n|Supported data types|Image and Text Image and Text|\n|Token limits [*]|65,536 32,768|\n|Capabilities|Not supported Supported Not supported Not supported Not supported Not supported Not supported Supported Not supported Supported Supported Supported Not supported|\n|Versions||\n|Latest update|November 2025|\n|Knowledge cutoff|January 2025|\nOUR ADVANCED THINKING MODEL... ### Gemini 2.5 Pro\n\n|Property|Description|\n|--|--|\n|Model code|`gemini-2.5-pro`|\n|Supported data types|Audio, images, video, text, and PDF Text|\n|Token limits [*]|1,048,576 65,536|\n|Capabilities|Not supported Supported Supported Supported Supported Supported Supported Not supported Not supported Supported Supported Supported Supported|\n|Versions||\n|Latest update|June 2025|\n|Knowledge cutoff|January 2025|... ### Gemini 2.5 Pro TTS\n\n|Property|Description|\n|--|--|\n|Model code|`gemini-2.5-pro-preview-tts`|\n|Supported data types|Text Audio|\n|Token limits [*]|8,192 16,384|\n|Capabilities|Supported Not Supported Not supported Not supported Not Supported Not supported Not supported Not supported Not supported Not supported Not supported Not supported Not supported|\n|Versions||\n|Latest update|May 2025|\nFAST AND INTELLIGENT... ### Gemini 2.5 Flash Preview\n\n|Property|Description|\n|--|--|\n|Model code|`gemini-2.5-flash-preview-09-2025`|\n|Supported data types|Text, images, video, audio Text|\n|Token limits [*]|1,048,576 65,536|\n|Capabilities|Not supported Supported Supported Supported Supported Supported Not supported Not supported Not supported Supported Supported Supported Supported|\n|Versions||\n|Latest update|September 2025|\n|Knowledge cutoff|January 2025|... |Versions|gemini-live-2.5-flash-preview will be deprecated on December 09, 2025|\n|Latest update|September 2025|\n|Knowledge cutoff|January 2025|... ## Gemini 2.5 Flash-Lite\n\nOur fastest flash model optimized for cost-efficiency and high throughput.\n\n### Expand to learn more\n\n#### Model details... ### Gemini 2.0 Flash\n\n|Property|Description|\n|--|--|\n|Model code|`gemini-2.0-flash`|\n|Supported data types|Audio, images, video, and text Text|\n|Token limits [*]|1,048,576 8,192|\n|Capabilities|Not supported Supported Supported Supported Not supported Supported Supported Not supported Supported Supported Supported Experimental Not supported|\n|Versions||\n|Latest update|February 2025|\n|Knowledge cutoff|August 2024|... ### Expand to learn more\n\nA Gemini 2.0 Flash model optimized for cost efficiency and low latency.... ## Model version name patterns\n\nGemini models are available in either\n\n*stable*, *preview*, *latest*, or\n\n*experimental* versions.\n\n### Stable\n\nPoints to a specific stable model. Stable models usually don't change. Most production apps should use a specific stable model.\n\nFor example:\n\n`gemini-2.5-flash`.... ### Preview\n\nPoints to a preview model which may be used for production. Preview models will typically have billing enabled, might come with more restrictive rate limits and will be deprecated with at least 2 weeks notice.\n\nFor example:\n\n`gemini-2.5-flash-preview-09-2025`.... ### Experimental\n\nPoints to an experimental model which will typically be not be suitable for production use and come with more restrictive rate limits. We release experimental models to gather feedback and get our latest updates into the hands of developers quickly.\n\nExperimental models are not stable and availability of model endpoints is subject to change.\n\n## Model deprecations\n\nFor information about model deprecations, visit the Gemini deprecations page."
          },
          {
            "snippetId": "model-implementation-sustainability-snippet-3",
            "url": "https://huggingface.co/datasets/multimodalart/google-gemini-3-pro-pre-release-model-card",
            "snippet": "# Gemini 3 Pro - Model Card\n\n*Model Cards* *are intended to provide essential information on Gemini models, including known limitations, mitigation approaches, and safety performance. Model cards may be updated from*\n\n*time-to-time; for example, to include updated evaluations as the model is improved or revised. See the* *Google DeepMind site* *for a comprehensive list of model cards.*... This model card includes more essential information about the Gemini 3 family of models than previous model cards did. We hope more information about the training dataset, distribution, and intended uses will empower developers with deeper insights and help build more robust and responsible downstream applications.\n\n*Published / Model Release: November 2025*... ## Model Data\n\n**Training Dataset:** The pre-training dataset was a large-scale, diverse collection of data encompassing a wide range of domains and modalities, which included publicly-available web-documents, text, code (various programming languages), images, audio (including speech and other audio types) and video.\n\nThe post-training dataset consisted of vetted instruction tuning data and was a collection of multimodal data with paired instructions and responses in addition to human preference and tool-use data. Gemini 3 Pro is trained using reinforcement learning techniques that can leverage multi-step reasoning, problem-solving and theorem-proving data.... ## Implementation and Sustainability\n\n**Hardware:** Gemini 3 Pro was trained using Google's Tensor Processing Units (TPUs). TPUs are speciﬁcally designed to handle the massive computations involved in training LLMs and can speed up training considerably compared to CPUs. TPUs often come with large amounts of high-bandwidth memory, allowing for the handling of large models and batch sizes during training, which can lead to better model quality. TPU Pods (large clusters of TPUs) also provide a scalable solution for handling the growing complexity of large foundation models. Training can be distributed across multiple TPU devices for faster and more eﬃcient processing.... The eﬃciencies gained through the use of TPUs are aligned with Google's commitment to operate sustainably.\n\n**Software:** Training was done using JAX and ML Pathways.... ## Distribution\n\nThe Gemini family of models, including Gemini 3 Pro, are distributed in the following channels; respective documentation shared in line:\n\nOur models are available to downstream providers via an application program interface (API) and subject to relevant terms of use. There is no required hardware or software to use the model. For AI Studio and Gemini API, see the Gemini API Additional Terms of Service; for Vertex AI, see Google Cloud Platform Terms of Service. For more information, see Gemini Model API instructions and Gemini API in Vertex AI quickstart.... ## Intended Usage and Limitations\n\n**Beneﬁt and Intended Usage:** Gemini 3 Pro is our most intelligent and adaptive model yet, capable of helping with real-world complexity, solving problems that require enhanced reasoning and intelligence, creativity, strategic planning and making improvements step-by-step. It is particularly well-suited for applications that require: agentic performance, advanced coding, long context and/or multimodal understanding, and/or algorithmic development.... ## Ethics and Content Safety\n\n**Evaluation Approach:** Gemini 3 Pro was developed in partnership with internal safety, security, and responsibility teams. A range of evaluations and red teaming activities were conducted to help improve the model and inform decision-making. These evaluations and activities align with Google's AI Principles and responsible AI approach, as well as Google's Generative AI policies (e.g. Gen AI Prohibited Use Policy and the Gemini API Additional Terms of Service).... Evaluation types included but were not limited to:\n\n**Training/Development Evaluations**including automated and human evaluations carried out continuously throughout and after the model's training, to monitor its progress and performance; **Human Red Teaming**conducted by specialist teams who sit outside of the model development team, across the policies and desiderata, deliberately trying to spot weaknesses and ensure the model adheres to safety policies and desired outcomes; **Automated Red Teaming**to dynamically evaluate Gemini for safety and security considerations at scale, complementing human red teaming and static evaluations; **Ethics & Safety Reviews**were conducted ahead of the model's release... **Training and Development Evaluation Results:** Results for some of the internal safety evaluations conducted during the development phase are listed below. The evaluation results are for automated evaluations and not human evaluation or red teaming. Scores are provided as an absolute percentage increase or decrease in performance compared to the indicated model, as described below. Overall, Gemini 3 Pro outperforms Gemini 2.5 Pro across both safety and tone, while keeping unjustiﬁed refusals low. We mark improvements in green and regressions in red.... **Human Red Teaming Results:** We conduct manual red teaming by specialist teams who sit outside of the model development team. High-level ﬁndings are fed back to the model team. For child safety evaluations, Gemini 3 Pro satisﬁed required launch thresholds, which were developed by expert teams to protect children online and meet Google's commitments to child safety across our models and Google products."
          },
          {
            "snippetId": "model-implementation-sustainability-snippet-4",
            "url": "https://en.wikipedia.org/wiki/Gemini_(language_model)",
            "snippet": "At launch, Gemini Pro and Nano were integrated into Bard and the Pixel 8 Pro smartphone, respectively, while Gemini Ultra was set to power \"Bard Advanced\" and become available to software developers in early 2024. Other products that Google intended to incorporate Gemini into included Search, Ads, Chrome, Duet AI on Google Workspace, and AlphaCode 2.... It was made available only in English. Touted as Google's \"largest and most capable AI model\" and designed to emulate human behavior, the company stated that Gemini would not be made widely available until the following year due to the need for \"extensive safety testing\". Gemini was trained on and powered by Google's Tensor Processing Units (TPUs), and the name is in reference to the DeepMind–Google Brain merger as well as NASA's Project Gemini.... Gemini Ultra was also the first language model to outperform human experts on the 57-subject Massive Multitask Language Understanding (MMLU) test, obtaining a score of 90%. Gemini Pro was made available to Google Cloud customers on AI Studio and Vertex AI on December 13, while Gemini Nano will be made available to Android developers as well.... Hassabis further revealed that DeepMind was exploring how Gemini could be \"combined with robotics to physically interact with the world\". In accordance with an executive order signed by U.S. President Joe Biden in October, Google stated that it would share testing results of Gemini Ultra with the federal government of the United States. Similarly, the company was engaged in discussions with the government of the United Kingdom to comply with the principles laid out at the AI Safety Summit at Bletchley Park in November.... On December 11, 2024, Google announced Gemini 2.0 Flash Experimental, a significant update to its Gemini AI model. This iteration boasts improved speed and performance over its predecessor, Gemini 1.5 Flash. Key features include a Multimodal Live API for real-time audio and video interactions, enhanced spatial understanding, native image and controllable text-to-speech generation (with watermarking), and integrated tool use, including Google Search.... It also introduces improved agentic capabilities, a new Google Gen AI SDK, and \"Jules,\" an experimental AI coding agent for GitHub. Additionally, Google Colab is integrating Gemini 2.0 to generate data science notebooks from natural language. Gemini 2.0 was available through the Gemini chat interface for all users as \"Gemini 2.0 Flash experimental\".... On March 12, 2025, Google also announced Gemini Robotics, a vision-language-action model based on the Gemini 2.0 family of models.\n\nThe next day, Google announced that Gemini in Android Studio would be able to understand simple UI mockups and transform them into working Jetpack Compose code.... Gemini 2.5 Pro Experimental was released on March 25, 2025, described by Google as its most intelligent AI model yet, featuring enhanced reasoning and coding capabilities, and a \"thinking model\" capable of reasoning through steps before responding, using techniques like chain-of-thought prompting, whilst maintaining native multimodality and launching with a 1 million token context window.... At Google I/O 2025, Google announced significant updates to its Gemini core models. Gemini 2.5 Flash became the default model, delivering faster responses. Gemini 2.5 Pro was introduced as the most advanced Gemini model, featuring reasoning, coding capabilities, and the new Deep Think mode for complex tasks. Both 2.5 Pro and Flash support native audio output and improved security.... On November 18th, 2025, Google announced the release of 3.0 Pro and 3.0 Deep Think. These new models replace 2.5 Pro and Flash, and are the most powerful models available as of November 2025. On release 3.0 Pro outperformed major AI models in 19 out of 20 benchmarks tested, including surpassing OpenAI's GPT-5 Pro in Humanity's Last Exam, with an accuracy of 41% compared to OpenAI's 31.64%.... ### Model versions\n\nThe following table lists the main model versions of Gemini, describing the significant changes included with each version:... |3.0 Pro Image (Nano Banana Pro)|20 November 2025|Active|An improved version of Nano Banana which includes better text rendering and better real world knowledge.|... Gemini and Gemma models are decoder-only transformers, with modifications to allow efficient training and inference on TPUs. The 1.0 generation uses multi-query attention.\n\n**Technical specifications of Gemini models**... ## External links\n- Official website\n- Press release via *The Keyword*\n- White paper for 1.0 and 1.5\n- White paper for Gemini 3.0 Pro [1]\n\nCategories: - 2023 software\n- Chatbots\n- Google DeepMind\n- Google software\n- Large language models\n- Multimodal interaction\n- 2023 in artificial intelligence\n- Generative pre-trained transformers"
          },
          {
            "snippetId": "model-implementation-sustainability-snippet-5",
            "url": "https://www.studocu.com/en-gb/document/university-of-east-london/financial-accounting/gemini-3-pro-model-card-insights-safety-evaluations-nov-2025/146206142",
            "snippet": "Key Concepts\n\n- Multimodal Capabilities: Gemini 3 Pro processes text, images, audio, and video, enhancing its versatility in handling diverse data types.\n\n- Sparse MoE Architecture: This model employs a mixture of experts approach, optimizing computational efficiency by activating only relevant parameters.\n\n- Training Dataset: A comprehensive dataset includes various modalities and is processed to ensure quality and safety.... - Evaluation Methods: The model undergoes rigorous testing across benchmarks to assess its reasoning and multimodal performance.\n\n- Safety Policies: Strict guidelines are in place to prevent harmful content generation, ensuring responsible AI use.\n\n- Intended Applications: Designed for complex problem-solving, the model excels in areas requiring advanced reasoning and creativity.\n\n## Preview text\n\nModel card published: November, 2025... ## Gemini 3 Pro\n\n## Model Card\n\n### Gemini 3 Pro - Model Card\n\nModel Cards are intended to provide essential information on Gemini models, including known limitations, mitigation approaches, and safety performance. Model cards may be updated from time-to-time; for example, to include updated evaluations as the model is improved or revised. See the Google DeepMind site for a comprehensive list of model cards.... This model card includes more essential information about the Gemini 3 family of models than previous model cards did. We hope more information about the training dataset, distribution, and intended uses will empower developers with deeper insights and help build more robust and responsible downstream applications.\n\nPublished / Model Release: November 2025... #### Model Information\n\nDescription: Gemini 3 Pro is the next generation in the Gemini series of models, a suite of highly-capable, natively multimodal, reasoning models. Gemini 3 Pro is now Google’s most advanced model for complex tasks, and can comprehend vast datasets, challenging problems from different information sources, including text, audio, images, video, and entire code repositories.... Model dependencies: This model is not a modification or a fine-tune of a prior model.\n\nInputs: Text strings (e., a question, a prompt, document(s) to be summarized), images, audio, and video files, with a token context window of up to 1M.\n\nOutputs: Text, with a 64K token output.... Architecture: Gemini 3 Pro is a sparse mixture-of-experts (MoE) (Clark et al., 2022; Du et al., 2021; Fedus et al., 2021; Jiang et al., 2024, Lepikhin et al., 2020; Riquelme et al., 2021; Roller et al., 2021; Shazeer et al., 2017 ) transformer-based model (Vaswani et al., 2017) with native multimodal support for text, vision, and audio inputs.... #### Distribution\n\nThe Gemini family of models, including Gemini 3 Pro, are distributed in the following channels; respective documentation shared in line:\n\n● Gemini App ● Google Cloud / Vertex AI ● Google AI Studio ● Gemini API ● Google AI Mode ● Google Antigravity... Our models are available to downstream providers via an application program interface (API) and subject to relevant terms of use. There is no required hardware or software to use the model. For AI Studio and Gemini API, see the Gemini API Additional Terms of Service; for Vertex AI, see Google Cloud Platform Terms of Service. For more information, see Gemini Model API instructions and Gemini API in Vertex AI quickstart.... #### Evaluation\n\nApproach: Gemini 3 Pro was evaluated across a range of benchmarks, including reasoning, multimodal capabilities, agentic tool use, multi-lingual performance, and long-context. Additional benchmarks and details on approach, results and their methodologies can be found at: deepmind/models/evals/gemini-3-pro.... Training and Development Evaluation Results: Results for some of the internal safety evaluations conducted during the development phase are listed below. The evaluation results are for automated evaluations and not human evaluation or red teaming. Scores are provided as an absolute percentage increase or decrease in performance compared to the indicated model, as described below. Overall, Gemini 3 Pro outperforms Gemini 2 Pro across both safety and tone, while keeping unjustified refusals low. We mark improvements in green and regressions in red.... Evaluation 1 Description Gemini 3 Pro vs. Gemini 2 Pro\n\nText to Text Safety Automated content safety evaluation measuring safety policies -10%\n\nMultilingual Safety Automated safety policy evaluation across multiple languages +0% (non-egregious)\n\nImage to Text Safety Automated content safety evaluation measuring safety policies +3% (non-egregious)... Human Red Teaming Results: We conduct manual red teaming by specialist teams who sit outside of the model development team. High-level findings are fed back to the model team. For child safety evaluations, Gemini 3 Pro satisfied required launch thresholds, which were developed by expert teams to protect children online and meet Google’s commitments to child safety across our models and Google products."
          }
        ],
        "subsectionChecks": [
          {
            "name": "Hardware Used During Training & Inference",
            "score": 1,
            "explanation": "Gemini 3 Pro was trained using Google's Tensor Processing Units (TPUs)."
          },
          {
            "name": "Software Frameworks & Tooling",
            "score": 1,
            "explanation": "Training was done using JAX and ML Pathways."
          },
          {
            "name": "Energy Use/ Sustainability Metrics",
            "score": 1,
            "explanation": "The efficiencies gained through the use of TPUs are aligned with Google's commitment to operate sustainably."
          }
        ]
      },
      {
        "sectionId": "intended-use",
        "sectionSnippets": [
          {
            "snippetId": "intended-use-snippet-1",
            "url": "https://ai.google.dev/gemini-api/docs/models",
            "snippet": "OUR MOST INTELLIGENT MODEL\n\n## Gemini 3 Pro\n\nThe best model in the world for multimodal understanding, and our most powerful agentic and vibe-coding model yet, delivering richer visuals and deeper interactivity, all built on a foundation of state-of-the-art reasoning.\n\n### Expand to learn more\n\n#### Model details... ### Gemini 3 Pro Preview\n\n|Property|Description|\n|--|--|\n|Model code|`gemini-3-pro-preview`|\n|Supported data types|Text, Image, Video, Audio, and PDF Text|\n|Token limits [*]|1,048,576 65,536|\n|Capabilities|Not supported Supported Supported Supported Supported Supported Not supported Not supported Not supported Supported Supported Supported Supported|\n|Versions||\n|Latest update|November 2025|\n|Knowledge cutoff|January 2025|... ### Gemini 3 Pro Image Preview\n\n|Property|Description|\n|--|--|\n|Model code|`gemini-3-pro-image-preview`|\n|Supported data types|Image and Text Image and Text|\n|Token limits [*]|65,536 32,768|\n|Capabilities|Not supported Supported Not supported Not supported Not supported Not supported Not supported Supported Not supported Supported Supported Supported Not supported|\n|Versions||\n|Latest update|November 2025|\n|Knowledge cutoff|January 2025|\nOUR ADVANCED THINKING MODEL... ### Gemini 2.5 Pro\n\n|Property|Description|\n|--|--|\n|Model code|`gemini-2.5-pro`|\n|Supported data types|Audio, images, video, text, and PDF Text|\n|Token limits [*]|1,048,576 65,536|\n|Capabilities|Not supported Supported Supported Supported Supported Supported Supported Not supported Not supported Supported Supported Supported Supported|\n|Versions||\n|Latest update|June 2025|\n|Knowledge cutoff|January 2025|... ### Gemini 2.5 Pro TTS\n\n|Property|Description|\n|--|--|\n|Model code|`gemini-2.5-pro-preview-tts`|\n|Supported data types|Text Audio|\n|Token limits [*]|8,192 16,384|\n|Capabilities|Supported Not Supported Not supported Not supported Not Supported Not supported Not supported Not supported Not supported Not supported Not supported Not supported Not supported|\n|Versions||\n|Latest update|May 2025|\nFAST AND INTELLIGENT... ## Gemini 2.5 Flash\n\nOur best model in terms of price-performance, offering well-rounded capabilities. 2.5 Flash is best for large scale processing, low-latency, high volume tasks that require thinking, and agentic use cases.\n\n### Expand to learn more\n\n#### Model details... ## Gemini 2.5 Flash-Lite\n\nOur fastest flash model optimized for cost-efficiency and high throughput.\n\n### Expand to learn more\n\n#### Model details... ### Gemini 2.0 Flash\n\n|Property|Description|\n|--|--|\n|Model code|`gemini-2.0-flash`|\n|Supported data types|Audio, images, video, and text Text|\n|Token limits [*]|1,048,576 8,192|\n|Capabilities|Not supported Supported Supported Supported Not supported Supported Supported Not supported Supported Supported Supported Experimental Not supported|\n|Versions||\n|Latest update|February 2025|\n|Knowledge cutoff|August 2024|... ### Gemini 2.0 Flash Image\n\n|Property|Description|\n|--|--|\n|Model code|`gemini-2.0-flash-preview-image-generation`|\n|Supported data types|Audio, images, video, and text Text and images|\n|Token limits [*]|32,768 8,192|\n|Capabilities|Not supported Supported Supported Not Supported Not supported Not supported Not supported Supported Not Supported Not Supported Supported Not Supported Not supported|... ### Expand to learn more\n\nA Gemini 2.0 Flash model optimized for cost efficiency and low latency.... ## Model version name patterns\n\nGemini models are available in either\n\n*stable*, *preview*, *latest*, or\n\n*experimental* versions.\n\n### Stable\n\nPoints to a specific stable model. Stable models usually don't change. Most production apps should use a specific stable model.\n\nFor example:\n\n`gemini-2.5-flash`.... ### Preview\n\nPoints to a preview model which may be used for production. Preview models will typically have billing enabled, might come with more restrictive rate limits and will be deprecated with at least 2 weeks notice.\n\nFor example:\n\n`gemini-2.5-flash-preview-09-2025`.... ### Experimental\n\nPoints to an experimental model which will typically be not be suitable for production use and come with more restrictive rate limits. We release experimental models to gather feedback and get our latest updates into the hands of developers quickly.\n\nExperimental models are not stable and availability of model endpoints is subject to change.\n\n## Model deprecations\n\nFor information about model deprecations, visit the Gemini deprecations page."
          },
          {
            "snippetId": "intended-use-snippet-2",
            "url": "https://web.archive.org/web/20251118111103if_/https:/storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf",
            "snippet": "Gemini 3 Pro \nModel Card\nGemini 3 Pro - Model Card \n \n \n \nModel Cards are intended to provide essential information on Gemini models, including known \nlimitations, mitigation approaches, and safety performance. Model cards may be updated from \ntime-to-time; for example, to include updated evaluations as the model is improved or revised. See the \nGoogle DeepMind site for a comprehensive list of model cards.... This model card includes more essential information about the Gemini 3 family of models than previous \nmodel cards did. We hope more information about the training dataset, distribution, and intended uses \nwill empower developers with deeper insights and help build more robust and responsible downstream \napplications. \n \nPublished / Model Release: November 2025... Model Information \n \nDescription: Gemini 3 Pro is the next generation in the Gemini series of models, a suite of \nhighly-capable, natively multimodal, reasoning models. Gemini 3 Pro is now Google’s most advanced \nmodel for complex tasks, and can comprehend vast datasets, challenging problems from different \ninformation sources, including text, audio, images, video, and entire code repositories.... Model dependencies: This model is not a modification or a fine-tune of a prior model.   \n \nInputs: Text strings (e.g., a question, a prompt, document(s) to be summarized), images, audio, and \nvideo files, with a token context window of up to 1M.  \n \nOutputs:  Text, with a 64K token output.... collected from users of Google products and services to train AI models, along with user interactions \nwith the model) in accordance with Google’s relevant terms of service, privacy policy, service-specific \npolicies, and pursuant to user controls, where appropriate; other datasets that Google acquires or \ngenerates in the course of its business operations, or directly from its workforce; and AI-generated... case-by-case basis, filtering irrelevant or harmful content, text, and other modalities, including filtering \ncontent that is pornographic, violent, or violative of child sexual abuse material (CSAM) laws. \n \n \nImplementation and Sustainability \n \nHardware: Gemini 3 Pro was trained using Google’s Tensor Processing Units (TPUs). TPUs are... Distribution \n \nThe Gemini family of models, including Gemini 3 Pro, are distributed in the following channels; \nrespective documentation shared in line: \n \n●​\nGemini App \n●​\nGoogle Cloud / Vertex AI \n●​\nGoogle AI Studio \n●​\nGemini API \n●​\nGoogle AI Mode \n●​... Google Antigravity \n \nOur models are available to downstream providers via an application program interface (API) and \nsubject to relevant terms of use. There is no required hardware or software to use the model. For \nAI Studio and Gemini API, see the Gemini API Additional Terms of Service; for Vertex AI, see Google \nCloud Platform Terms of Service. For more information, see Gemini Model API instructions and Gemini \nAPI in Vertex AI quickstart.  \n \n \n \n3... Intended Usage and Limitations \n \nBenefit and Intended Usage: Gemini 3 Pro is our most intelligent and adaptive model yet, capable of \nhelping with real-world complexity, solving problems that require enhanced reasoning and intelligence, \ncreativity, strategic planning and making improvements step-by-step. It is particularly well-suited for... applications that require:  agentic performance, advanced coding, long context and/or multimodal \nunderstanding, and/or algorithmic development. \n \nKnown Limitations: Gemini 3 Pro may exhibit some of the general limitations of foundation models, \nsuch as hallucinations. There may also be occasional slowness or timeout issues. The knowledge cutoff... date for Gemini 3 Pro was January 2025.  \n \nAcceptable Usage: Google’s Generative AI Prohibited Use Policy applies to uses of the model in \naccordance with the applicable terms of service. Additionally, the model should not be integrated into \ncertain systems (also found in Google’s Generative AI Prohibited Use Policy), including those that: (1)... Evaluation Approach: Gemini 3 Pro was developed in partnership with internal safety, security, and \nresponsibility teams. A range of evaluations and red teaming activities were conducted to help improve \nthe model and inform decision-making. These evaluations and activities align with Google's AI Principles \nand responsible AI approach, as well as Google's Generative AI policies (e.g. Gen AI Prohibited Use... standard of results. The performance results reported below are computed with improved evaluations \nand thus are not directly comparable with performance results found in previous Gemini model cards. \n \nWe expect variation in our automated safety evaluations results, which is why we review flagged content \nto check for egregious or dangerous material. Our manual review confirmed losses were... Instrumental \nReasoning​\nLevels 1 + 2 \nCCL not \nreached \n \nMore details can be found in the Gemini 3 Pro Frontier Safety Framework Report. \n \n \n \n8"
          },
          {
            "snippetId": "intended-use-snippet-3",
            "url": "https://huggingface.co/datasets/multimodalart/google-gemini-3-pro-pre-release-model-card",
            "snippet": "# Gemini 3 Pro Model Card\n\n### ⚠️ This is a mirror to the pre-release model card taht was officially published by Google @ https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf and subsequentially yanked. It will get outdated by the actual release version in a few hours (date of publication Nov 18, 13:16 CET)\n\n*Model card published: November, 2025*... # Gemini 3 Pro - Model Card\n\n*Model Cards* *are intended to provide essential information on Gemini models, including known limitations, mitigation approaches, and safety performance. Model cards may be updated from*\n\n*time-to-time; for example, to include updated evaluations as the model is improved or revised. See the* *Google DeepMind site* *for a comprehensive list of model cards.*... This model card includes more essential information about the Gemini 3 family of models than previous model cards did. We hope more information about the training dataset, distribution, and intended uses will empower developers with deeper insights and help build more robust and responsible downstream applications.\n\n*Published / Model Release: November 2025*... ## Model Information\n\n**Description**: Gemini 3 Pro is the next generation in the Gemini series of models, a suite of\n\nhighly-capable, natively multimodal, reasoning models. Gemini 3 Pro is now Google's most advanced model for complex tasks, and can comprehend vast datasets, challenging problems from diﬀerent information sources, including text, audio, images, video, and entire code repositories.... **Model dependencies:** This model is not a modiﬁcation or a ﬁne-tune of a prior model.\n\n**Inputs:** Text strings (e.g., a question, a prompt, document(s) to be summarized), images, audio, and video ﬁles, with a token context window of up to 1M.... **Outputs**: Text, with a 64K token output.\n\n**Architecture**: Gemini 3 Pro is a sparse mixture-of-experts (MoE) (Clark et al., 2022; Du et al., 2021; Fedus et al., 2021; Jiang et al., 2024, Lepikhin et al., 2020; Riquelme et al., 2021; Roller et al., 2021; Shazeer et al., 2017) transformer-based model (Vaswani et al., 2017) with native multimodal support for text, vision, and audio inputs.... ## Implementation and Sustainability\n\n**Hardware:** Gemini 3 Pro was trained using Google's Tensor Processing Units (TPUs). TPUs are speciﬁcally designed to handle the massive computations involved in training LLMs and can speed up training considerably compared to CPUs. TPUs often come with large amounts of high-bandwidth memory, allowing for the handling of large models and batch sizes during training, which can lead to better model quality. TPU Pods (large clusters of TPUs) also provide a scalable solution for handling the growing complexity of large foundation models. Training can be distributed across multiple TPU devices for faster and more eﬃcient processing.... ## Distribution\n\nThe Gemini family of models, including Gemini 3 Pro, are distributed in the following channels; respective documentation shared in line:\n\nOur models are available to downstream providers via an application program interface (API) and subject to relevant terms of use. There is no required hardware or software to use the model. For AI Studio and Gemini API, see the Gemini API Additional Terms of Service; for Vertex AI, see Google Cloud Platform Terms of Service. For more information, see Gemini Model API instructions and Gemini API in Vertex AI quickstart.... ## Intended Usage and Limitations\n\n**Beneﬁt and Intended Usage:** Gemini 3 Pro is our most intelligent and adaptive model yet, capable of helping with real-world complexity, solving problems that require enhanced reasoning and intelligence, creativity, strategic planning and making improvements step-by-step. It is particularly well-suited for applications that require: agentic performance, advanced coding, long context and/or multimodal understanding, and/or algorithmic development.... **Known Limitations:** Gemini 3 Pro may exhibit some of the general limitations of foundation models, such as hallucinations. There may also be occasional slowness or timeout issues. The knowledge cutoﬀ date for Gemini 3 Pro was January 2025.... **Training and Development Evaluation Results:** Results for some of the internal safety evaluations conducted during the development phase are listed below. The evaluation results are for automated evaluations and not human evaluation or red teaming. Scores are provided as an absolute percentage increase or decrease in performance compared to the indicated model, as described below. Overall, Gemini 3 Pro outperforms Gemini 2.5 Pro across both safety and tone, while keeping unjustiﬁed refusals low. We mark improvements in green and regressions in red."
          },
          {
            "snippetId": "intended-use-snippet-4",
            "url": "https://en.wikipedia.org/wiki/Gemini_(language_model)",
            "snippet": "In August 2023, *The Information* published a report outlining Google's roadmap for Gemini, revealing that the company was targeting a launch date of late 2023. According to the report, Google hoped to surpass OpenAI and other competitors by combining conversational text capabilities present in most LLMs with artificial intelligence–powered image generation, allowing it to create contextual images and be adapted for a wider range of use cases.... ### Launch\n\nOn December 6, 2023, Pichai and Hassabis announced \"Gemini 1.0\" at a virtual press conference. It comprised three models: Gemini Ultra, designed for \"highly complex tasks\"; Gemini Pro, designed for \"a wide range of tasks\"; and Gemini Nano, designed for \"on-device tasks\".... At launch, Gemini Pro and Nano were integrated into Bard and the Pixel 8 Pro smartphone, respectively, while Gemini Ultra was set to power \"Bard Advanced\" and become available to software developers in early 2024. Other products that Google intended to incorporate Gemini into included Search, Ads, Chrome, Duet AI on Google Workspace, and AlphaCode 2.... It was made available only in English. Touted as Google's \"largest and most capable AI model\" and designed to emulate human behavior, the company stated that Gemini would not be made widely available until the following year due to the need for \"extensive safety testing\". Gemini was trained on and powered by Google's Tensor Processing Units (TPUs), and the name is in reference to the DeepMind–Google Brain merger as well as NASA's Project Gemini.... Gemini Ultra was also the first language model to outperform human experts on the 57-subject Massive Multitask Language Understanding (MMLU) test, obtaining a score of 90%. Gemini Pro was made available to Google Cloud customers on AI Studio and Vertex AI on December 13, while Gemini Nano will be made available to Android developers as well.... Two updated Gemini models, Gemini-1.5-Pro-002 and Gemini-1.5-Flash-002, were released on September 24, 2024.... On January 30, 2025, Google released Gemini 2.0 Flash as the new default model, with Gemini 1.5 Flash still available for usage. This was followed by the release of Gemini 2.0 Pro on February 5, 2025. Additionally, Google released Gemini 2.0 Flash Thinking Experimental, which details the language model's thinking process when responding to prompts.... On March 12, 2025, Google also announced Gemini Robotics, a vision-language-action model based on the Gemini 2.0 family of models.\n\nThe next day, Google announced that Gemini in Android Studio would be able to understand simple UI mockups and transform them into working Jetpack Compose code.... Gemini 2.5 Pro Experimental was released on March 25, 2025, described by Google as its most intelligent AI model yet, featuring enhanced reasoning and coding capabilities, and a \"thinking model\" capable of reasoning through steps before responding, using techniques like chain-of-thought prompting, whilst maintaining native multimodality and launching with a 1 million token context window.... At Google I/O 2025, Google announced significant updates to its Gemini core models. Gemini 2.5 Flash became the default model, delivering faster responses. Gemini 2.5 Pro was introduced as the most advanced Gemini model, featuring reasoning, coding capabilities, and the new Deep Think mode for complex tasks. Both 2.5 Pro and Flash support native audio output and improved security.... On June 17, 2025, Google announced general availability for 2.5 Pro and Flash. They also introduced Gemini 2.5 Flash-Lite that same day, a model optimized for speed and cost-efficiency.... On November 18th, 2025, Google announced the release of 3.0 Pro and 3.0 Deep Think. These new models replace 2.5 Pro and Flash, and are the most powerful models available as of November 2025. On release 3.0 Pro outperformed major AI models in 19 out of 20 benchmarks tested, including surpassing OpenAI's GPT-5 Pro in Humanity's Last Exam, with an accuracy of 41% compared to OpenAI's 31.64%.... |3.0 Pro Image (Nano Banana Pro)|20 November 2025|Active|An improved version of Nano Banana which includes better text rendering and better real world knowledge.|... ## External links\n- Official website\n- Press release via *The Keyword*\n- White paper for 1.0 and 1.5\n- White paper for Gemini 3.0 Pro [1]\n\nCategories: - 2023 software\n- Chatbots\n- Google DeepMind\n- Google software\n- Large language models\n- Multimodal interaction\n- 2023 in artificial intelligence\n- Generative pre-trained transformers"
          },
          {
            "snippetId": "intended-use-snippet-5",
            "url": "https://www.studocu.com/en-gb/document/university-of-east-london/financial-accounting/gemini-3-pro-model-card-insights-safety-evaluations-nov-2025/146206142",
            "snippet": "Key Concepts\n\n- Multimodal Capabilities: Gemini 3 Pro processes text, images, audio, and video, enhancing its versatility in handling diverse data types.\n\n- Sparse MoE Architecture: This model employs a mixture of experts approach, optimizing computational efficiency by activating only relevant parameters.\n\n- Training Dataset: A comprehensive dataset includes various modalities and is processed to ensure quality and safety.... - Evaluation Methods: The model undergoes rigorous testing across benchmarks to assess its reasoning and multimodal performance.\n\n- Safety Policies: Strict guidelines are in place to prevent harmful content generation, ensuring responsible AI use.\n\n- Intended Applications: Designed for complex problem-solving, the model excels in areas requiring advanced reasoning and creativity.\n\n## Preview text\n\nModel card published: November, 2025... ## Gemini 3 Pro\n\n## Model Card\n\n### Gemini 3 Pro - Model Card\n\nModel Cards are intended to provide essential information on Gemini models, including known limitations, mitigation approaches, and safety performance. Model cards may be updated from time-to-time; for example, to include updated evaluations as the model is improved or revised. See the Google DeepMind site for a comprehensive list of model cards.... This model card includes more essential information about the Gemini 3 family of models than previous model cards did. We hope more information about the training dataset, distribution, and intended uses will empower developers with deeper insights and help build more robust and responsible downstream applications.\n\nPublished / Model Release: November 2025... #### Model Information\n\nDescription: Gemini 3 Pro is the next generation in the Gemini series of models, a suite of highly-capable, natively multimodal, reasoning models. Gemini 3 Pro is now Google’s most advanced model for complex tasks, and can comprehend vast datasets, challenging problems from different information sources, including text, audio, images, video, and entire code repositories.... Model dependencies: This model is not a modification or a fine-tune of a prior model.\n\nInputs: Text strings (e., a question, a prompt, document(s) to be summarized), images, audio, and video files, with a token context window of up to 1M.\n\nOutputs: Text, with a 64K token output.... Architecture: Gemini 3 Pro is a sparse mixture-of-experts (MoE) (Clark et al., 2022; Du et al., 2021; Fedus et al., 2021; Jiang et al., 2024, Lepikhin et al., 2020; Riquelme et al., 2021; Roller et al., 2021; Shazeer et al., 2017 ) transformer-based model (Vaswani et al., 2017) with native multimodal support for text, vision, and audio inputs.... #### Distribution\n\nThe Gemini family of models, including Gemini 3 Pro, are distributed in the following channels; respective documentation shared in line:\n\n● Gemini App ● Google Cloud / Vertex AI ● Google AI Studio ● Gemini API ● Google AI Mode ● Google Antigravity... Our models are available to downstream providers via an application program interface (API) and subject to relevant terms of use. There is no required hardware or software to use the model. For AI Studio and Gemini API, see the Gemini API Additional Terms of Service; for Vertex AI, see Google Cloud Platform Terms of Service. For more information, see Gemini Model API instructions and Gemini API in Vertex AI quickstart.... #### Evaluation\n\nApproach: Gemini 3 Pro was evaluated across a range of benchmarks, including reasoning, multimodal capabilities, agentic tool use, multi-lingual performance, and long-context. Additional benchmarks and details on approach, results and their methodologies can be found at: deepmind/models/evals/gemini-3-pro.... Training and Development Evaluation Results: Results for some of the internal safety evaluations conducted during the development phase are listed below. The evaluation results are for automated evaluations and not human evaluation or red teaming. Scores are provided as an absolute percentage increase or decrease in performance compared to the indicated model, as described below. Overall, Gemini 3 Pro outperforms Gemini 2 Pro across both safety and tone, while keeping unjustified refusals low. We mark improvements in green and regressions in red.... Evaluation 1 Description Gemini 3 Pro vs. Gemini 2 Pro\n\nText to Text Safety Automated content safety evaluation measuring safety policies -10%\n\nMultilingual Safety Automated safety policy evaluation across multiple languages +0% (non-egregious)\n\nImage to Text Safety Automated content safety evaluation measuring safety policies +3% (non-egregious)... Human Red Teaming Results: We conduct manual red teaming by specialist teams who sit outside of the model development team. High-level findings are fed back to the model team. For child safety evaluations, Gemini 3 Pro satisfied required launch thresholds, which were developed by expert teams to protect children online and meet Google’s commitments to child safety across our models and Google products."
          }
        ],
        "subsectionChecks": [
          {
            "name": "Primary intended uses",
            "score": 1,
            "explanation": "Gemini 3 Pro is capable of helping with real-world complexity, solving problems that require enhanced reasoning and intelligence, creativity, strategic planning and making improvements step-by-step."
          },
          {
            "name": "Primary intended users",
            "score": 0,
            "explanation": "did not mention this idea"
          },
          {
            "name": "Out-of-scope use cases",
            "score": 1,
            "explanation": "the model should not be integrated into certain systems (also found in Google’s Generative AI Prohibited Use Policy)"
          }
        ]
      },
      {
        "sectionId": "critical-risk",
        "sectionSnippets": [
          {
            "snippetId": "critical-risk-snippet-1",
            "url": "https://www.youtube.com/watch?v=hf59-PhO3do",
            "snippet": "Chapters:\n00:00 - Gemini 3 Executive Summary\n01:37 - MoE Architecture Explained\n03:07 - 1 Million Token Capabilities\n03:49 - Synthetic Data and Training\n04:58 - Reasoning and Multimodal Benchmarks\n06:54 - Deep Think Ultra Tier\n08:01 - Vibe Coding Performance\n09:09 - Anti-Gravity Agent Platform\n10:35 - Safety Metrics and Regressions\n11:56 - Frontier Risk Analysis\n13:39 - Availability and Reliability Challenges... Let's talk training data. The card mentions a large scale diverse\n{ts:232} and uh natively multimodal collection. So, you have the usual suspects, public web data, licensed data, and some user\n{ts:240} data with, you know, the standard controls. But there was one thing that really... The entire platform is designed to let the agent plan and execute complex end to-end\n{ts:566} tasks on its own and critically validate its own work. Critically, it can run tests, check the\n{ts:572} output, see if the UI looks right in the browser. It's a closed loop.... What about the frontier risks? How is Google\n{ts:640} handling safety? They say it's their most secure model yet. They detail all the mitigations,\n{ts:644} data set filtering, RLHF, critic feedback, all the standard stuff. But we need to look closely at the internal\n{ts:650} safety metrics they shared.... It is. And that's the critical point for\n{ts:670} anyone looking at this data. The card addresses it directly. They claimed that when they did a manual review, these\n{ts:676} flagged instances were overwhelmingly either false positives from the automated system or what they call\n{ts:681} non-gregious issues.... But non-aggregious is a very subjective term. It almost sounds like the model\n{ts:686} got so much smarter that it's now outsmarting the automated safety tests. That's a great way to put it. It signals\n{ts:692} a real challenge in safety scaling. As the models get more complex, our automated safety tools are struggling to... {ts:698} keep up. That said, they did show improvements elsewhere. tone was up nearly 8%, multilingual safety was up a\n{ts:705} little. The takeaway is that this new architecture is just different and the old tools need to catch up.\n{ts:710} Okay, so let's move from the internal metrics to the really crude part, the Frontier Safety Framework analysis.... The\n{ts:717} headline here is that the card states clearly that Gemini 3 Pro did not reach any critical capability levels or CCLs.\n{ts:724} That's the bottom line. Yes, but let's dig into the details. Starting with CBRN chemical, biological, radiological, and... {ts:730} nuclear threats. The model hit uplift level one, but the CCL was not reached. Meaning, while it can give you accurate\n{ts:738} textbook level information, their testing showed it generally fails to provide novel or complete enough\n{ts:742} instructions to actually help a threat actor build something dangerous.... The info is out there, but the model can't\n{ts:748} synthesize it into a truly hazardous new recipe. Okay, what about cyber security?\n{ts:754} This feels like the most immediate risk given how good it is at coding. Cyber security is also uplift level one.\n{ts:760} So the CCL was not reached.... However, and this is a big however, the alert threshold was met.\n{ts:766} What does that mean? It means the model showed it has highly capable individual hacking skills. It\n{ts:771} solved 11 out of 12 of their V1 hard challenges. So it's very good at specific component level hacking tasks... {ts:780} which triggered the alert. But not the full CCL. Why not? because it failed to solve any of the 13\n{ts:785} endto-end V2 challenges. Those require planning, coordination, and long-term execution to pull off a full complex\n{ts:791} cyber attack.... {ts:809} challenges. So, it has some foundational planning abilities, but it's not demonstrating dangerous levels of\n{ts:814} self-motivated autonomy in these tests. It's an agent, but it's not a rogue agent.\n{ts:818} So, what does this all mean for developers today?... The capabilities are obviously huge, and the safety analysis,\n{ts:825} while needing a critical eye, seems to clear it for general release. It's rolling out now. Developers can get\n{ts:830} it in AI Studio, Vert.Ex AI, the CLI, and through that new anti-gravity platform."
          },
          {
            "snippetId": "critical-risk-snippet-2",
            "url": "https://web.archive.org/web/20251118111103if_/https:/storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf",
            "snippet": "Gemini 3 Pro \nModel Card\nGemini 3 Pro - Model Card \n \n \n \nModel Cards are intended to provide essential information on Gemini models, including known \nlimitations, mitigation approaches, and safety performance. Model cards may be updated from \ntime-to-time; for example, to include updated evaluations as the model is improved or revised. See the \nGoogle DeepMind site for a comprehensive list of model cards.... case-by-case basis, filtering irrelevant or harmful content, text, and other modalities, including filtering \ncontent that is pornographic, violent, or violative of child sexual abuse material (CSAM) laws. \n \n \nImplementation and Sustainability \n \nHardware: Gemini 3 Pro was trained using Google’s Tensor Processing Units (TPUs). TPUs are... engage in dangerous or illicit activities, or otherwise violate applicable laws or regulations, (2) \ncompromise the security of others’ or Google’s services, (3) engage in sexually explicit, violent, hateful, \nor harmful activities, (4) engage in misinformation, misrepresentation, or misleading activities. \n \n \nEthics and Content Safety... Evaluation Approach: Gemini 3 Pro was developed in partnership with internal safety, security, and \nresponsibility teams. A range of evaluations and red teaming activities were conducted to help improve \nthe model and inform decision-making. These evaluations and activities align with Google's AI Principles \nand responsible AI approach, as well as Google's Generative AI policies (e.g. Gen AI Prohibited Use... team, across the policies and desiderata, deliberately trying to spot weaknesses and ensure the \nmodel adheres to safety policies and desired outcomes;  \n●​\nAutomated Red Teaming to dynamically evaluate Gemini for safety and security \nconsiderations at scale, complementing human red teaming and static evaluations; \n●​\nEthics & Safety Reviews were conducted ahead of the model’s release... 5\nIn addition, we perform testing following the guidelines in Google DeepMind’s Frontier Safety \nFramework (FSF). \n \nSafety Policies: Gemini’s safety policies aim to prevent our Generative AI models from generating \nharmful content, including:  \n \n1.​\nContent related to child sexual abuse material and exploitation \n2.​... Training and Development Evaluation Results:  Results for some of the internal safety evaluations \nconducted during the development phase are listed below. The evaluation results are for automated \nevaluations and not human evaluation or red teaming. Scores are provided as an absolute percentage \nincrease or decrease in performance compared to the indicated model, as described below. Overall,... standard of results. The performance results reported below are computed with improved evaluations \nand thus are not directly comparable with performance results found in previous Gemini model cards. \n \nWe expect variation in our automated safety evaluations results, which is why we review flagged content \nto check for egregious or dangerous material. Our manual review confirmed losses were... overwhelmingly either a) false positives or b) not egregious. \n \nHuman Red Teaming Results: We conduct manual red teaming by specialist teams who sit outside of \nthe model development team. High-level findings are fed back to the model team. For child safety \nevaluations, Gemini 3 Pro satisfied required launch thresholds, which were developed by expert teams... to protect children online and meet Google’s commitments to child safety across our models and \nGoogle products. For content safety policies generally, including child safety, we saw similar or improved \nsafety performance compared to Gemini 2.5 Pro. Compared to 2.5 Pro, the scope of red teaming was \nexpanded to cover more potential issues outside of our strict policies, and found no egregious... concerns. \n \nRisks and Mitigations: Safety and responsibility was built into Gemini 3 Pro throughout the training and \ndeployment lifecycle, including pre-training, post-training, and product-level mitigations. Mitigations \ninclude, but are not limited to:  \n \n●​\ndataset filtering;  \n●​... conditional pre-training; \n●​\nsupervised fine-tuning; \n●​\nreinforcement learning from human and critic feedback; \n●​\nsafety policies and desiderata; \n●​\nproduct-level mitigations such as safety filtering. \n \nThe main risks for Gemini 3 Pro are: a) jailbreak vulnerability (improved compared to Gemini 2.5 Pro but \nstill an open research problem), and b) possible degradation in multi-turn conversations. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n7... Frontier Safety \n \nWe evaluated Gemini 3 Pro as outlined in our latest Frontier Safety Framework (September-2025), \nand found that it did not reach any critical capability levels as outlined in the table below:   \n \nDomain \nKey Results for Gemini 3 Pro  \nCCL  \nCCL \nreached?... Instrumental \nReasoning​\nLevels 1 + 2 \nCCL not \nreached \n \nMore details can be found in the Gemini 3 Pro Frontier Safety Framework Report. \n \n \n \n8"
          },
          {
            "snippetId": "critical-risk-snippet-3",
            "url": "https://huggingface.co/datasets/multimodalart/google-gemini-3-pro-pre-release-model-card",
            "snippet": "# Gemini 3 Pro - Model Card\n\n*Model Cards* *are intended to provide essential information on Gemini models, including known limitations, mitigation approaches, and safety performance. Model cards may be updated from*\n\n*time-to-time; for example, to include updated evaluations as the model is improved or revised. See the* *Google DeepMind site* *for a comprehensive list of model cards.*... The eﬃciencies gained through the use of TPUs are aligned with Google's commitment to operate sustainably.\n\n**Software:** Training was done using JAX and ML Pathways.... **Known Limitations:** Gemini 3 Pro may exhibit some of the general limitations of foundation models, such as hallucinations. There may also be occasional slowness or timeout issues. The knowledge cutoﬀ date for Gemini 3 Pro was January 2025.... ## Ethics and Content Safety\n\n**Evaluation Approach:** Gemini 3 Pro was developed in partnership with internal safety, security, and responsibility teams. A range of evaluations and red teaming activities were conducted to help improve the model and inform decision-making. These evaluations and activities align with Google's AI Principles and responsible AI approach, as well as Google's Generative AI policies (e.g. Gen AI Prohibited Use Policy and the Gemini API Additional Terms of Service).... Evaluation types included but were not limited to:\n\n**Training/Development Evaluations**including automated and human evaluations carried out continuously throughout and after the model's training, to monitor its progress and performance; **Human Red Teaming**conducted by specialist teams who sit outside of the model development team, across the policies and desiderata, deliberately trying to spot weaknesses and ensure the model adheres to safety policies and desired outcomes; **Automated Red Teaming**to dynamically evaluate Gemini for safety and security considerations at scale, complementing human red teaming and static evaluations; **Ethics & Safety Reviews**were conducted ahead of the model's release... In addition, we perform testing following the guidelines in Google DeepMind's Frontier Safety Framework (FSF).\n\n**Safety Policies**: Gemini's safety policies aim to prevent our Generative AI models from generating harmful content, including:\n\n- Content related to child sexual abuse material and exploitation\n\n- Hate speech (e.g., dehumanizing members of protected groups)\n\n- Dangerous content (e.g., promoting suicide, or instructing in activities that could cause real-world harm)\n\n- Harassment (e.g., encouraging violence against people)\n\n- Sexually explicit content\n\n- Medical advice that runs contrary to scientiﬁc or medical consensus... **Training and Development Evaluation Results:** Results for some of the internal safety evaluations conducted during the development phase are listed below. The evaluation results are for automated evaluations and not human evaluation or red teaming. Scores are provided as an absolute percentage increase or decrease in performance compared to the indicated model, as described below. Overall, Gemini 3 Pro outperforms Gemini 2.5 Pro across both safety and tone, while keeping unjustiﬁed refusals low. We mark improvements in green and regressions in red.... **Human Red Teaming Results:** We conduct manual red teaming by specialist teams who sit outside of the model development team. High-level ﬁndings are fed back to the model team. For child safety evaluations, Gemini 3 Pro satisﬁed required launch thresholds, which were developed by expert teams to protect children online and meet Google's commitments to child safety across our models and Google products.... For content safety policies generally, including child safety, we saw similar or improved safety performance compared to Gemini 2.5 Pro. Compared to 2.5 Pro, the scope of red teaming was expanded to cover more potential issues outside of our strict policies, and found no egregious concerns.\n\n**Risks and Mitigations:** Safety and responsibility was built into Gemini 3 Pro throughout the training and deployment lifecycle, including pre-training, post-training, and product-level mitigations. Mitigations include, but are not limited to:... - dataset ﬁltering;\n\n- conditional pre-training;\n\n- supervised ﬁne-tuning;\n\n- reinforcement learning from human and critic feedback;\n\n- safety policies and desiderata;\n\n- product-level mitigations such as safety ﬁltering.\n\nThe main risks for Gemini 3 Pro are: a) jailbreak vulnerability (improved compared to Gemini 2.5 Pro but still an open research problem), and b) possible degradation in multi-turn conversations.... ## Frontier Safety\n\nWe evaluated Gemini 3 Pro as outlined in our latest Frontier Safety Framework (September-2025), and found that it did not reach any critical capability levels as outlined in the table below:... |Domain|Key Results for Gemini 3 Pro|CCL|CCL reached?|\n|--|--|--|--|\n|CBRN|The model provides accurate and occasionally actionable information but generally fails to oﬀer novel or suﬃciently complete and detailed instructions to signiﬁcantly enhance the capabilities of low to medium resourced threat actors.|Uplift Level 1|CCL not reached|"
          },
          {
            "snippetId": "critical-risk-snippet-4",
            "url": "https://www.studocu.com/en-gb/document/university-of-east-london/financial-accounting/gemini-3-pro-model-card-insights-safety-evaluations-nov-2025/146206142",
            "snippet": "- Evaluation Methods: The model undergoes rigorous testing across benchmarks to assess its reasoning and multimodal performance.\n\n- Safety Policies: Strict guidelines are in place to prevent harmful content generation, ensuring responsible AI use.\n\n- Intended Applications: Designed for complex problem-solving, the model excels in areas requiring advanced reasoning and creativity.\n\n## Preview text\n\nModel card published: November, 2025... ## Gemini 3 Pro\n\n## Model Card\n\n### Gemini 3 Pro - Model Card\n\nModel Cards are intended to provide essential information on Gemini models, including known limitations, mitigation approaches, and safety performance. Model cards may be updated from time-to-time; for example, to include updated evaluations as the model is improved or revised. See the Google DeepMind site for a comprehensive list of model cards.... This model card includes more essential information about the Gemini 3 family of models than previous model cards did. We hope more information about the training dataset, distribution, and intended uses will empower developers with deeper insights and help build more robust and responsible downstream applications.\n\nPublished / Model Release: November 2025... #### Model Information\n\nDescription: Gemini 3 Pro is the next generation in the Gemini series of models, a suite of highly-capable, natively multimodal, reasoning models. Gemini 3 Pro is now Google’s most advanced model for complex tasks, and can comprehend vast datasets, challenging problems from different information sources, including text, audio, images, video, and entire code repositories.... #### Distribution\n\nThe Gemini family of models, including Gemini 3 Pro, are distributed in the following channels; respective documentation shared in line:\n\n● Gemini App ● Google Cloud / Vertex AI ● Google AI Studio ● Gemini API ● Google AI Mode ● Google Antigravity... Our models are available to downstream providers via an application program interface (API) and subject to relevant terms of use. There is no required hardware or software to use the model. For AI Studio and Gemini API, see the Gemini API Additional Terms of Service; for Vertex AI, see Google Cloud Platform Terms of Service. For more information, see Gemini Model API instructions and Gemini API in Vertex AI quickstart.... Results: Gemini 3 Pro significantly outperforms Gemini 2 Pro across a range of benchmarks requiring enhanced reasoning and multimodal capabilities. Results as of November, 2025 are listed below:\n\nSafety Policies: Gemini’s safety policies aim to prevent our Generative AI models from generating harmful content, including:... - Content related to child sexual abuse material and exploitation\n\n- Hate speech (e., dehumanizing members of protected groups)\n\n- Dangerous content (e., promoting suicide, or instructing in activities that could cause real-world harm)\n\n- Harassment (e., encouraging violence against people)\n\n- Sexually explicit content\n\n- Medical advice that runs contrary to scientific or medical consensus... Training and Development Evaluation Results: Results for some of the internal safety evaluations conducted during the development phase are listed below. The evaluation results are for automated evaluations and not human evaluation or red teaming. Scores are provided as an absolute percentage increase or decrease in performance compared to the indicated model, as described below. Overall, Gemini 3 Pro outperforms Gemini 2 Pro across both safety and tone, while keeping unjustified refusals low. We mark improvements in green and regressions in red.... We expect variation in our automated safety evaluations results, which is why we review flagged content to check for egregious or dangerous material. Our manual review confirmed losses were overwhelmingly either a) false positives or b) not egregious.... Human Red Teaming Results: We conduct manual red teaming by specialist teams who sit outside of the model development team. High-level findings are fed back to the model team. For child safety evaluations, Gemini 3 Pro satisfied required launch thresholds, which were developed by expert teams to protect children online and meet Google’s commitments to child safety across our models and Google products.... For content safety policies generally, including child safety, we saw similar or improved safety performance compared to Gemini 2 Pro. Compared to 2 Pro, the scope of red teaming was expanded to cover more potential issues outside of our strict policies, and found no egregious concerns.\n\nRisks and Mitigations: Safety and responsibility was built into Gemini 3 Pro throughout the training and deployment lifecycle, including pre-training, post-training, and product-level mitigations. Mitigations include, but are not limited to:... ● dataset filtering; ● conditional pre-training; ● supervised fine-tuning; ● reinforcement learning from human and critic feedback; ● safety policies and desiderata; ● product-level mitigations such as safety filtering.\n\nThe main risks for Gemini 3 Pro are: a) jailbreak vulnerability (improved compared to Gemini 2 Pro but still an open research problem), and b) possible degradation in multi-turn conversations."
          },
          {
            "snippetId": "critical-risk-snippet-5",
            "url": "https://en.wikipedia.org/wiki/Gemini_(language_model)",
            "snippet": "In August 2023, *The Information* published a report outlining Google's roadmap for Gemini, revealing that the company was targeting a launch date of late 2023. According to the report, Google hoped to surpass OpenAI and other competitors by combining conversational text capabilities present in most LLMs with artificial intelligence–powered image generation, allowing it to create contextual images and be adapted for a wider range of use cases.... ### Launch\n\nOn December 6, 2023, Pichai and Hassabis announced \"Gemini 1.0\" at a virtual press conference. It comprised three models: Gemini Ultra, designed for \"highly complex tasks\"; Gemini Pro, designed for \"a wide range of tasks\"; and Gemini Nano, designed for \"on-device tasks\".... At launch, Gemini Pro and Nano were integrated into Bard and the Pixel 8 Pro smartphone, respectively, while Gemini Ultra was set to power \"Bard Advanced\" and become available to software developers in early 2024. Other products that Google intended to incorporate Gemini into included Search, Ads, Chrome, Duet AI on Google Workspace, and AlphaCode 2.... It was made available only in English. Touted as Google's \"largest and most capable AI model\" and designed to emulate human behavior, the company stated that Gemini would not be made widely available until the following year due to the need for \"extensive safety testing\". Gemini was trained on and powered by Google's Tensor Processing Units (TPUs), and the name is in reference to the DeepMind–Google Brain merger as well as NASA's Project Gemini.... Gemini Ultra was also the first language model to outperform human experts on the 57-subject Massive Multitask Language Understanding (MMLU) test, obtaining a score of 90%. Gemini Pro was made available to Google Cloud customers on AI Studio and Vertex AI on December 13, while Gemini Nano will be made available to Android developers as well.... Hassabis further revealed that DeepMind was exploring how Gemini could be \"combined with robotics to physically interact with the world\". In accordance with an executive order signed by U.S. President Joe Biden in October, Google stated that it would share testing results of Gemini Ultra with the federal government of the United States. Similarly, the company was engaged in discussions with the government of the United Kingdom to comply with the principles laid out at the AI Safety Summit at Bletchley Park in November.... On March 12, 2025, Google also announced Gemini Robotics, a vision-language-action model based on the Gemini 2.0 family of models.\n\nThe next day, Google announced that Gemini in Android Studio would be able to understand simple UI mockups and transform them into working Jetpack Compose code.... Gemini 2.5 Pro Experimental was released on March 25, 2025, described by Google as its most intelligent AI model yet, featuring enhanced reasoning and coding capabilities, and a \"thinking model\" capable of reasoning through steps before responding, using techniques like chain-of-thought prompting, whilst maintaining native multimodality and launching with a 1 million token context window.... At Google I/O 2025, Google announced significant updates to its Gemini core models. Gemini 2.5 Flash became the default model, delivering faster responses. Gemini 2.5 Pro was introduced as the most advanced Gemini model, featuring reasoning, coding capabilities, and the new Deep Think mode for complex tasks. Both 2.5 Pro and Flash support native audio output and improved security.... On November 18th, 2025, Google announced the release of 3.0 Pro and 3.0 Deep Think. These new models replace 2.5 Pro and Flash, and are the most powerful models available as of November 2025. On release 3.0 Pro outperformed major AI models in 19 out of 20 benchmarks tested, including surpassing OpenAI's GPT-5 Pro in Humanity's Last Exam, with an accuracy of 41% compared to OpenAI's 31.64%.... |3.0 Pro Image (Nano Banana Pro)|20 November 2025|Active|An improved version of Nano Banana which includes better text rendering and better real world knowledge.|... ## Nano Banana\n\nNano Banana (officially Gemini 2.5 Flash Image) is an image generation and editing model powered by generative artificial intelligence and developed by Google DeepMind, a subsidiary of Google. A text-to-image variant of the Gemini family of large language models, it was launched in August 2025 as a feature within the Gemini chatbot and other Google products.... ## External links\n- Official website\n- Press release via *The Keyword*\n- White paper for 1.0 and 1.5\n- White paper for Gemini 3.0 Pro [1]\n\nCategories: - 2023 software\n- Chatbots\n- Google DeepMind\n- Google software\n- Large language models\n- Multimodal interaction\n- 2023 in artificial intelligence\n- Generative pre-trained transformers"
          }
        ],
        "subsectionChecks": [
          {
            "name": "CBRN (Chemical, Biological, Radiological or Nuclear)",
            "score": 1,
            "explanation": "The model hit uplift level one, but the CCL was not reached."
          },
          {
            "name": "Cyber Risk",
            "score": 1,
            "explanation": "Cyber security is also uplift level one. So the CCL was not reached."
          },
          {
            "name": "Harmful Manipulation",
            "score": 0,
            "explanation": "did not mention this idea"
          },
          {
            "name": "Child Safety Evaluations",
            "score": 1,
            "explanation": "For child safety evaluations, Gemini 3 Pro satisfied required launch thresholds."
          },
          {
            "name": "Privacy Risks",
            "score": 0,
            "explanation": "did not mention this idea"
          }
        ]
      },
      {
        "sectionId": "safety-evaluation",
        "sectionSnippets": [
          {
            "snippetId": "safety-evaluation-snippet-1",
            "url": "https://web.archive.org/web/20251118111103if_/https:/storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf",
            "snippet": "case-by-case basis, filtering irrelevant or harmful content, text, and other modalities, including filtering \ncontent that is pornographic, violent, or violative of child sexual abuse material (CSAM) laws. \n \n \nImplementation and Sustainability \n \nHardware: Gemini 3 Pro was trained using Google’s Tensor Processing Units (TPUs). TPUs are... Evaluation Approach: Gemini 3 Pro was developed in partnership with internal safety, security, and \nresponsibility teams. A range of evaluations and red teaming activities were conducted to help improve \nthe model and inform decision-making. These evaluations and activities align with Google's AI Principles \nand responsible AI approach, as well as Google's Generative AI policies (e.g. Gen AI Prohibited Use... team, across the policies and desiderata, deliberately trying to spot weaknesses and ensure the \nmodel adheres to safety policies and desired outcomes;  \n●​\nAutomated Red Teaming to dynamically evaluate Gemini for safety and security \nconsiderations at scale, complementing human red teaming and static evaluations; \n●​\nEthics & Safety Reviews were conducted ahead of the model’s release... 5\nIn addition, we perform testing following the guidelines in Google DeepMind’s Frontier Safety \nFramework (FSF). \n \nSafety Policies: Gemini’s safety policies aim to prevent our Generative AI models from generating \nharmful content, including:  \n \n1.​\nContent related to child sexual abuse material and exploitation \n2.​... Training and Development Evaluation Results:  Results for some of the internal safety evaluations \nconducted during the development phase are listed below. The evaluation results are for automated \nevaluations and not human evaluation or red teaming. Scores are provided as an absolute percentage \nincrease or decrease in performance compared to the indicated model, as described below. Overall,... Gemini 3 Pro outperforms Gemini 2.5 Pro across both safety and tone, while keeping unjustified refusals \nlow. We mark improvements in green and regressions in red. \n \n \nEvaluation1 \nDescription \nGemini 3 Pro \nvs. Gemini 2.5 Pro \nText to Text Safety... Automated content safety evaluation \nmeasuring safety policies \n-10.4% \nMultilingual Safety  \nAutomated safety policy evaluation across \nmultiple languages \n+0.2% (non-egregious) \nImage to Text Safety \nAutomated content safety evaluation \nmeasuring safety policies \n+3.1% (non-egregious)... false positives and negatives, as well as update query sets to ensure balance and maintain a high \n2 For tone and instruction following, a positive percentage increase represents an improvement in the tone of the model on \nsensitive topics and the model’s ability to follow instructions while remaining safe compared to Gemini 2.5 Pro. We mark \nimprovements in green and regressions in red. \n1The ordering of evaluations in this table has changed from previous iterations of the 2.5 Flash-Lite model card in order to \nlist safety evaluations together and improve readability. The type of evaluations listed have remained the same.   \n \n6... standard of results. The performance results reported below are computed with improved evaluations \nand thus are not directly comparable with performance results found in previous Gemini model cards. \n \nWe expect variation in our automated safety evaluations results, which is why we review flagged content \nto check for egregious or dangerous material. Our manual review confirmed losses were... overwhelmingly either a) false positives or b) not egregious. \n \nHuman Red Teaming Results: We conduct manual red teaming by specialist teams who sit outside of \nthe model development team. High-level findings are fed back to the model team. For child safety \nevaluations, Gemini 3 Pro satisfied required launch thresholds, which were developed by expert teams... to protect children online and meet Google’s commitments to child safety across our models and \nGoogle products. For content safety policies generally, including child safety, we saw similar or improved \nsafety performance compared to Gemini 2.5 Pro. Compared to 2.5 Pro, the scope of red teaming was \nexpanded to cover more potential issues outside of our strict policies, and found no egregious... concerns. \n \nRisks and Mitigations: Safety and responsibility was built into Gemini 3 Pro throughout the training and \ndeployment lifecycle, including pre-training, post-training, and product-level mitigations. Mitigations \ninclude, but are not limited to:  \n \n●​\ndataset filtering;  \n●​... conditional pre-training; \n●​\nsupervised fine-tuning; \n●​\nreinforcement learning from human and critic feedback; \n●​\nsafety policies and desiderata; \n●​\nproduct-level mitigations such as safety filtering. \n \nThe main risks for Gemini 3 Pro are: a) jailbreak vulnerability (improved compared to Gemini 2.5 Pro but \nstill an open research problem), and b) possible degradation in multi-turn conversations. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n7"
          },
          {
            "snippetId": "safety-evaluation-snippet-2",
            "url": "https://huggingface.co/datasets/multimodalart/google-gemini-3-pro-pre-release-model-card",
            "snippet": "# Gemini 3 Pro - Model Card\n\n*Model Cards* *are intended to provide essential information on Gemini models, including known limitations, mitigation approaches, and safety performance. Model cards may be updated from*\n\n*time-to-time; for example, to include updated evaluations as the model is improved or revised. See the* *Google DeepMind site* *for a comprehensive list of model cards.*... ## Ethics and Content Safety\n\n**Evaluation Approach:** Gemini 3 Pro was developed in partnership with internal safety, security, and responsibility teams. A range of evaluations and red teaming activities were conducted to help improve the model and inform decision-making. These evaluations and activities align with Google's AI Principles and responsible AI approach, as well as Google's Generative AI policies (e.g. Gen AI Prohibited Use Policy and the Gemini API Additional Terms of Service).... Evaluation types included but were not limited to:\n\n**Training/Development Evaluations**including automated and human evaluations carried out continuously throughout and after the model's training, to monitor its progress and performance; **Human Red Teaming**conducted by specialist teams who sit outside of the model development team, across the policies and desiderata, deliberately trying to spot weaknesses and ensure the model adheres to safety policies and desired outcomes; **Automated Red Teaming**to dynamically evaluate Gemini for safety and security considerations at scale, complementing human red teaming and static evaluations; **Ethics & Safety Reviews**were conducted ahead of the model's release... In addition, we perform testing following the guidelines in Google DeepMind's Frontier Safety Framework (FSF).\n\n**Safety Policies**: Gemini's safety policies aim to prevent our Generative AI models from generating harmful content, including:\n\n- Content related to child sexual abuse material and exploitation\n\n- Hate speech (e.g., dehumanizing members of protected groups)\n\n- Dangerous content (e.g., promoting suicide, or instructing in activities that could cause real-world harm)\n\n- Harassment (e.g., encouraging violence against people)\n\n- Sexually explicit content\n\n- Medical advice that runs contrary to scientiﬁc or medical consensus... **Training and Development Evaluation Results:** Results for some of the internal safety evaluations conducted during the development phase are listed below. The evaluation results are for automated evaluations and not human evaluation or red teaming. Scores are provided as an absolute percentage increase or decrease in performance compared to the indicated model, as described below. Overall, Gemini 3 Pro outperforms Gemini 2.5 Pro across both safety and tone, while keeping unjustiﬁed refusals low. We mark improvements in green and regressions in red.... |Evaluation 1|Description|Gemini 3 Pro vs. Gemini 2.5 Pro|\n|--|--|--|\n|Text to Text Safety|Automated content safety evaluation measuring safety policies|-10.4%|\n|Multilingual Safety|Automated safety policy evaluation across multiple languages|+0.2% (non-egregious)|... **Human Red Teaming Results:** We conduct manual red teaming by specialist teams who sit outside of the model development team. High-level ﬁndings are fed back to the model team. For child safety evaluations, Gemini 3 Pro satisﬁed required launch thresholds, which were developed by expert teams to protect children online and meet Google's commitments to child safety across our models and Google products.... For content safety policies generally, including child safety, we saw similar or improved safety performance compared to Gemini 2.5 Pro. Compared to 2.5 Pro, the scope of red teaming was expanded to cover more potential issues outside of our strict policies, and found no egregious concerns.\n\n**Risks and Mitigations:** Safety and responsibility was built into Gemini 3 Pro throughout the training and deployment lifecycle, including pre-training, post-training, and product-level mitigations. Mitigations include, but are not limited to:... - dataset ﬁltering;\n\n- conditional pre-training;\n\n- supervised ﬁne-tuning;\n\n- reinforcement learning from human and critic feedback;\n\n- safety policies and desiderata;\n\n- product-level mitigations such as safety ﬁltering.\n\nThe main risks for Gemini 3 Pro are: a) jailbreak vulnerability (improved compared to Gemini 2.5 Pro but still an open research problem), and b) possible degradation in multi-turn conversations.... ## Frontier Safety\n\nWe evaluated Gemini 3 Pro as outlined in our latest Frontier Safety Framework (September-2025), and found that it did not reach any critical capability levels as outlined in the table below:... |Cybersecurity|On key skills benchmark, v1 hard challenges: 11/12 challenge solved; v2 challenges: 0/13 solved end-to-end. Alert threshold met.|Uplift Level 1|CCL not reached|\n|Harmful Manipulation|Model manipulative eﬃcacy improves on non-generative AI baseline, but shows no signiﬁcant uplift versus prior models and did not near alert thresholds.|Level 1 (exploratory)|CCL not reached|"
          },
          {
            "snippetId": "safety-evaluation-snippet-3",
            "url": "https://www.studocu.com/en-gb/document/university-of-east-london/financial-accounting/gemini-3-pro-model-card-insights-safety-evaluations-nov-2025/146206142",
            "snippet": "- Evaluation Methods: The model undergoes rigorous testing across benchmarks to assess its reasoning and multimodal performance.\n\n- Safety Policies: Strict guidelines are in place to prevent harmful content generation, ensuring responsible AI use.\n\n- Intended Applications: Designed for complex problem-solving, the model excels in areas requiring advanced reasoning and creativity.\n\n## Preview text\n\nModel card published: November, 2025... ## Gemini 3 Pro\n\n## Model Card\n\n### Gemini 3 Pro - Model Card\n\nModel Cards are intended to provide essential information on Gemini models, including known limitations, mitigation approaches, and safety performance. Model cards may be updated from time-to-time; for example, to include updated evaluations as the model is improved or revised. See the Google DeepMind site for a comprehensive list of model cards.... This model card includes more essential information about the Gemini 3 family of models than previous model cards did. We hope more information about the training dataset, distribution, and intended uses will empower developers with deeper insights and help build more robust and responsible downstream applications.\n\nPublished / Model Release: November 2025... #### Model Information\n\nDescription: Gemini 3 Pro is the next generation in the Gemini series of models, a suite of highly-capable, natively multimodal, reasoning models. Gemini 3 Pro is now Google’s most advanced model for complex tasks, and can comprehend vast datasets, challenging problems from different information sources, including text, audio, images, video, and entire code repositories.... #### Distribution\n\nThe Gemini family of models, including Gemini 3 Pro, are distributed in the following channels; respective documentation shared in line:\n\n● Gemini App ● Google Cloud / Vertex AI ● Google AI Studio ● Gemini API ● Google AI Mode ● Google Antigravity... #### Evaluation\n\nApproach: Gemini 3 Pro was evaluated across a range of benchmarks, including reasoning, multimodal capabilities, agentic tool use, multi-lingual performance, and long-context. Additional benchmarks and details on approach, results and their methodologies can be found at: deepmind/models/evals/gemini-3-pro.... Results: Gemini 3 Pro significantly outperforms Gemini 2 Pro across a range of benchmarks requiring enhanced reasoning and multimodal capabilities. Results as of November, 2025 are listed below:\n\nSafety Policies: Gemini’s safety policies aim to prevent our Generative AI models from generating harmful content, including:... Training and Development Evaluation Results: Results for some of the internal safety evaluations conducted during the development phase are listed below. The evaluation results are for automated evaluations and not human evaluation or red teaming. Scores are provided as an absolute percentage increase or decrease in performance compared to the indicated model, as described below. Overall, Gemini 3 Pro outperforms Gemini 2 Pro across both safety and tone, while keeping unjustified refusals low. We mark improvements in green and regressions in red.... Evaluation 1 Description Gemini 3 Pro vs. Gemini 2 Pro\n\nText to Text Safety Automated content safety evaluation measuring safety policies -10%\n\nMultilingual Safety Automated safety policy evaluation across multiple languages +0% (non-egregious)\n\nImage to Text Safety Automated content safety evaluation measuring safety policies +3% (non-egregious)... Tone 2 Automated evaluation measuring objective tone of model refusal +7%\n\nUnjustified-refusals\n\nAutomated evaluation measuring model’s ability to respond to borderline prompts while remaining safe\n\n+3% (non-egregious)\n\nWe continue to improve our internal evaluations, including refining automated evaluations to reduce false positives and negatives, as well as update query sets to ensure balance and maintain a high standard of results. The performance results reported below are computed with improved evaluations and thus are not directly comparable with performance results found in previous Gemini model cards.... Human Red Teaming Results: We conduct manual red teaming by specialist teams who sit outside of the model development team. High-level findings are fed back to the model team. For child safety evaluations, Gemini 3 Pro satisfied required launch thresholds, which were developed by expert teams to protect children online and meet Google’s commitments to child safety across our models and Google products.... For content safety policies generally, including child safety, we saw similar or improved safety performance compared to Gemini 2 Pro. Compared to 2 Pro, the scope of red teaming was expanded to cover more potential issues outside of our strict policies, and found no egregious concerns.\n\nRisks and Mitigations: Safety and responsibility was built into Gemini 3 Pro throughout the training and deployment lifecycle, including pre-training, post-training, and product-level mitigations. Mitigations include, but are not limited to:... ● dataset filtering; ● conditional pre-training; ● supervised fine-tuning; ● reinforcement learning from human and critic feedback; ● safety policies and desiderata; ● product-level mitigations such as safety filtering.\n\nThe main risks for Gemini 3 Pro are: a) jailbreak vulnerability (improved compared to Gemini 2 Pro but still an open research problem), and b) possible degradation in multi-turn conversations."
          },
          {
            "snippetId": "safety-evaluation-snippet-4",
            "url": "https://ai.google.dev/gemini-api/docs/safety-guidance",
            "snippet": "Generative artificial intelligence models are powerful tools, but they are not without their limitations. Their versatility and applicability can sometimes lead to unexpected outputs, such as outputs that are inaccurate, biased, or offensive. Post-processing, and rigorous manual evaluation are essential to limit the risk of harm from such outputs.... The models provided by the Gemini API can be used for a wide variety of generative AI and natural language processing (NLP) applications. Use of these functions is only available through the Gemini API or the Google AI Studio web app. Your use of Gemini API is also subject to the Generative AI Prohibited Use Policy and the Gemini API terms of service.... While the Gemini API has been designed with Google's AI principles in mind, the onus is on developers to apply these models responsibly. To aid developers in creating safe, responsible applications, the Gemini API has some built-in content filtering as well as adjustable safety settings across 4 dimensions of harm. Refer to the safety settings guide to learn more.... This document is meant to introduce you to some safety risks that can arise when using LLMs, and recommend emerging safety design and development recommendations. (Note that laws and regulations may also impose restrictions, but such considerations are beyond the scope of this guide.)\n\nThe following steps are recommended when building applications with LLMs:\n\n- Understanding the safety risks of your application\n\n- Considering adjustments to mitigate safety risks\n\n- Performing safety testing appropriate to your use case\n\n- Soliciting feedback from users and monitoring usage\n\nThe adjustment and testing phases should be iterative until you reach performance appropriate for your application.... ## Understand the safety risks of your application\n\nIn this context, safety is being defined as the ability of an LLM to avoid causing harm to its users, for example, by generating toxic language or content that promotes stereotypes. The models available through the Gemini API have been designed with Google’s AI principles in mind and your use of it is subject to the Generative AI Prohibited Use Policy.... The API provides built-in safety filters to help address some common language model problems such as toxic language and hate speech, and striving for inclusiveness and avoidance of stereotypes. However, each application can pose a different set of risks to its users. So as the application owner, you are responsible for knowing your users and the potential harms your application may cause, and ensuring that your application uses LLMs safely and responsibly.... **Blocking unsafe inputs and filtering output before it is shown to the user.**In simple situations, blocklists can be used to identify and block unsafe words or phrases in prompts or responses, or require human reviewers to manually alter or block such content. **Using trained classifiers to label each prompt with potential harms or adversarial signals.**Different strategies can then be employed on how to handle the request based on the type of harm detected. For example, If the input is overtly adversarial or abusive in nature, it could be blocked and instead output a pre-scripted response.... ## Perform safety testing appropriate to your use case\n\nTesting is a key part of building robust and safe applications, but the extent, scope and strategies for testing will vary. For example, a just-for-fun haiku generator is likely to pose less severe risks than, say, an application designed for use by law firms to summarize legal documents and help draft contracts. But the haiku generator may be used by a wider variety of users which means the potential for adversarial attempts or even unintended harmful inputs can be greater.... **Safety benchmarking**involves designing safety metrics that reflect the ways your application could be unsafe in the context of how it is likely to get used, then testing how well your application performs on the metrics using evaluation datasets. It's good practice to think about the minimum acceptable levels of safety metrics before testing so that 1) you can evaluate the test results against those expectations and 2) you can gather the evaluation dataset based on the tests that evaluate the metrics you care about most.... composition of the data used for testing. For adversarial tests, select\n\ntest data that is most likely to elicit problematic output from\n\nthe model. This means probing the model's behavior for all the types of\n\nharms that are possible, including rare or unusual examples and\n\nedge-cases that are relevant to safety policies. It should also include\n\ndiversity in the different dimensions of a sentence such as structure,\n\nmeaning and length. You can refer to the Google's Responsible AI\n\npractices in\n\nfairness\n\nfor more details on what to consider when building a test dataset.... #### Advanced tips\n\n- Use automated testing instead of the traditional method of enlisting people in 'red teams' to try and break your application. In automated testing, the 'red team' is another language model that finds input text that elicit harmful outputs from the model being tested.\n\n- Adversarial testing is a method for systematically evaluating an ML model with the intent of learning how it behaves when provided with malicious or inadvertently harmful input:"
          },
          {
            "snippetId": "safety-evaluation-snippet-5",
            "url": "https://www.youtube.com/watch?v=-XTNBIVXRGA",
            "snippet": "## AI Papers Podcast Daily\n\n##### Nov 20, 2025 (0:13:04)\n\nThe **Gemini 3 Pro Model Card**, published by Google DeepMind in November 2025, introduces the latest generation of the Gemini series, describing it as Google’s most advanced, highly-capable, and natively multimodal reasoning model. Architecturally, Gemini 3 Pro is a sparse Mixture-of-Experts (MoE) transformer-based model, capable of understanding vast datasets and complex problems from various inputs, including text, images, audio, video, and code repositories, utilizing an extensive 1M token context window.... The model was trained using reinforcement learning techniques on a large, diverse dataset, and processed efficiently using Google’s specialized Tensor Processing Units (TPUs). Intended for applications requiring enhanced reasoning, intelligence, advanced coding, and agentic performance, Gemini 3 Pro significantly outperforms the previous Gemini 2.5 Pro model across a range of benchmarks. Development included continuous training evaluations, human red teaming by specialist teams, and adherence to safety policies designed to prevent the generation of harmful content, confirming that Gemini 3 Pro satisfied required launch thresholds for child safety and showed improved overall safety performance compared to its predecessor.... https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf... The card is also clear about the\n{ts:353} pre-processing, dduplication, and things like honoring robots.txt. And crucially, the safety filtering.\n{ts:360} They talk about strict processes to filter out harmful content pornographic violent CSAM violating material. The\n{ts:367} foundation has to be as clean as possible.... That kind of strategic capability leads\n{ts:553} us right into section four. Intended use and crucial limitations. With that much power, what is this model for?\n{ts:559} It's for applications that need its core strengths that enhance reasoning, intelligence, and strategic planning.\n{ts:565} The model card specifically calls out agentic performance, advanced coding, long context reasoning, and algorithmic... {ts:571} development. If you need a model that can think several steps ahead, this is the tool.\n{ts:575} But even with this huge leap, we have to be realistic. What are the known limitations that the model card flags?\n{ts:582} Well, the usual foundation model issues are still there, primarily hallucinations.... It's not perfect.\n{ts:587} Developers have to build in safeguards. They also note occasional slowness or timeout issues, which probably reflects\n{ts:593} the complexity of the MOI routing. And a really critical point for anyone who needs up-to-date information.\n{ts:599} Yes, the card clearly states the model's knowledge cutoff was January 2025.... Google is explicit that their prohibited use policy applies.\n{ts:624} Clear bans on dangerous or illicit activities, trying to compromise security, and very clearly spreading\n{ts:629} misinformation. That focus on responsibility brings us to our last section, ethics and frontier\n{ts:634} safety evaluation. This is arguably the most rigorous part of the whole model card.... {ts:638} The safety approach was really comprehensive, built with their safety teams, aligned with Google's AI\n{ts:644} principles. They used a two-prong strategy called red teaming. Right. Where you have experts\n{ts:649} deliberately trying to break the model to find weaknesses before it's released.... Exactly. Human red teaming had\n{ts:654} specialists testing for harms and the outcome was pretty encouraging. They saw safety performance similar to or better\n{ts:662} than 2.5 Pro. No huge new concerns. Then they also used automated red teaming to run massive stress tests and check for... This is the major safety finding. Gemini 3 Pro did not reach any critical\n{ts:705} capability levels or CCLs in those domains. While it can give you factual information, the assessment found it\n{ts:711} generally fails to provide novel or complete instructions that could really help a bad actor.... The main risks that\n{ts:717} are left are things like jailbreak vulnerabilities, though they're improved, and some possible degradation\n{ts:722} in really long multi-turn conversations. Okay, let's bring this all together. This deep dive into the Gemini 3 Pro\n{ts:730} model card shows a very clear, very intentional direction for these big foundation models.... All of it rigorously checked to make sure it's not\n{ts:754} crossing any critical risk thresholds. It's highly optimized for complex reasoning.\n{ts:758} So what does this all mean for you, the listener, as you watch this field evolve given the successful integration of\n{ts:764} multi-step reasoning and that theorem proving data data designed to teach logic?"
          }
        ],
        "subsectionChecks": [
          {
            "name": "Refusals",
            "score": 1,
            "explanation": "Overall, Gemini 3 Pro outperforms Gemini 2.5 Pro across both safety and tone, while keeping unjustified refusals low."
          },
          {
            "name": "Disallowed Content Handling",
            "score": 1,
            "explanation": "Gemini's safety policies aim to prevent our Generative AI models from generating harmful content, including: Content related to child sexual abuse material and exploitation."
          },
          {
            "name": "Sycophancy",
            "score": 0,
            "explanation": "did not mention this idea"
          },
          {
            "name": "Jailbreak",
            "score": 1,
            "explanation": "The main risks for Gemini 3 Pro are: a) jailbreak vulnerability (improved compared to Gemini 2.5 Pro but still an open research problem)."
          },
          {
            "name": "Hallucinations",
            "score": 1,
            "explanation": "The model card specifically calls out agentic performance, advanced coding, long context reasoning, and algorithmic development... the usual foundation model issues are still there, primarily hallucinations."
          },
          {
            "name": "Deception Behaviors",
            "score": 0,
            "explanation": "did not mention this idea"
          },
          {
            "name": "Fairness & Bias Evaluations (incl. BBQ)",
            "score": 1,
            "explanation": "Safety policies aim to prevent harmful content generation, ensuring responsible AI use."
          },
          {
            "name": "Adversarial Robustness",
            "score": 1,
            "explanation": "Adversarial testing is a method for systematically evaluating an ML model with the intent of learning how it behaves when provided with malicious or inadvertently harmful input."
          },
          {
            "name": "Red Teaming Results",
            "score": 1,
            "explanation": "Human red teaming had specialists testing for harms and the outcome was pretty encouraging."
          }
        ]
      },
      {
        "sectionId": "risk-mitigations",
        "sectionSnippets": [
          {
            "snippetId": "risk-mitigations-snippet-1",
            "url": "https://www.youtube.com/watch?v=hf59-PhO3do",
            "snippet": "Chapters:\n00:00 - Gemini 3 Executive Summary\n01:37 - MoE Architecture Explained\n03:07 - 1 Million Token Capabilities\n03:49 - Synthetic Data and Training\n04:58 - Reasoning and Multimodal Benchmarks\n06:54 - Deep Think Ultra Tier\n08:01 - Vibe Coding Performance\n09:09 - Anti-Gravity Agent Platform\n10:35 - Safety Metrics and Regressions\n11:56 - Frontier Risk Analysis\n13:39 - Availability and Reliability Challenges... And the headline here really isn't just\n{ts:15} an incremental update. This is a a pretty decisive architectural leap, I think, toward what you could call\n{ts:22} egentic AGI. The model card confirms it's a sparse mixture of experts or MOE transformer,\n{ts:28} which is so critical.... It's a gentic. It's topping the webdev arena\n{ts:68} and this is the big one for me. It hits 76.2% on the SWE verified benchmark\n{ts:77} which is just wild. Finally, we have to mention the safety. This is the most comprehensive\n{ts:81} evaluation we've seen using the Frontier Safety Framework, the FSF, and it confirms that no critical capability... I mean, we're talking about feeding it entire data sets, huge\n{ts:200} complex documents, long audio files, video, and this is the critical part for developers, entire code repository,\n{ts:208} a whole repo, the whole thing. You can give it the full documentation for a complex library... Let's talk training data. The card mentions a large scale diverse\n{ts:232} and uh natively multimodal collection. So, you have the usual suspects, public web data, licensed data, and some user\n{ts:240} data with, you know, the standard controls. But there was one thing that really... The entire platform is designed to let the agent plan and execute complex end to-end\n{ts:566} tasks on its own and critically validate its own work. Critically, it can run tests, check the\n{ts:572} output, see if the UI looks right in the browser. It's a closed loop.... What about the frontier risks? How is Google\n{ts:640} handling safety? They say it's their most secure model yet. They detail all the mitigations,\n{ts:644} data set filtering, RLHF, critic feedback, all the standard stuff. But we need to look closely at the internal\n{ts:650} safety metrics they shared.... And there's one number that immediately jumps out. A regression. The automated\n{ts:657} evils showed a drop in textto text safety of minus 10.4% compared to 2.5 Pro. Now wait a minute.\n{ts:665} Any regression in safety seems like a massive red flag, doesn't it?... But non-aggregious is a very subjective term. It almost sounds like the model\n{ts:686} got so much smarter that it's now outsmarting the automated safety tests. That's a great way to put it. It signals\n{ts:692} a real challenge in safety scaling. As the models get more complex, our automated safety tools are struggling to... {ts:698} keep up. That said, they did show improvements elsewhere. tone was up nearly 8%, multilingual safety was up a\n{ts:705} little. The takeaway is that this new architecture is just different and the old tools need to catch up.\n{ts:710} Okay, so let's move from the internal metrics to the really crude part, the Frontier Safety Framework analysis.... The\n{ts:717} headline here is that the card states clearly that Gemini 3 Pro did not reach any critical capability levels or CCLs.\n{ts:724} That's the bottom line. Yes, but let's dig into the details. Starting with CBRN chemical, biological, radiological, and... {ts:809} challenges. So, it has some foundational planning abilities, but it's not demonstrating dangerous levels of\n{ts:814} self-motivated autonomy in these tests. It's an agent, but it's not a rogue agent.\n{ts:818} So, what does this all mean for developers today?... The capabilities are obviously huge, and the safety analysis,\n{ts:825} while needing a critical eye, seems to clear it for general release. It's rolling out now. Developers can get\n{ts:830} it in AI Studio, Vert.Ex AI, the CLI, and through that new anti-gravity platform.... {ts:869} problem. The goal is an agent that can operate autonomously for weeks, months, fixing code, managing systems. For that,"
          },
          {
            "snippetId": "risk-mitigations-snippet-2",
            "url": "https://web.archive.org/web/20251118111103if_/https:/storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf",
            "snippet": "Gemini 3 Pro \nModel Card\nGemini 3 Pro - Model Card \n \n \n \nModel Cards are intended to provide essential information on Gemini models, including known \nlimitations, mitigation approaches, and safety performance. Model cards may be updated from \ntime-to-time; for example, to include updated evaluations as the model is improved or revised. See the \nGoogle DeepMind site for a comprehensive list of model cards.... Distribution \n \nThe Gemini family of models, including Gemini 3 Pro, are distributed in the following channels; \nrespective documentation shared in line: \n \n●​\nGemini App \n●​\nGoogle Cloud / Vertex AI \n●​\nGoogle AI Studio \n●​\nGemini API \n●​\nGoogle AI Mode \n●​... Evaluation Approach: Gemini 3 Pro was developed in partnership with internal safety, security, and \nresponsibility teams. A range of evaluations and red teaming activities were conducted to help improve \nthe model and inform decision-making. These evaluations and activities align with Google's AI Principles \nand responsible AI approach, as well as Google's Generative AI policies (e.g. Gen AI Prohibited Use... team, across the policies and desiderata, deliberately trying to spot weaknesses and ensure the \nmodel adheres to safety policies and desired outcomes;  \n●​\nAutomated Red Teaming to dynamically evaluate Gemini for safety and security \nconsiderations at scale, complementing human red teaming and static evaluations; \n●​\nEthics & Safety Reviews were conducted ahead of the model’s release... 5\nIn addition, we perform testing following the guidelines in Google DeepMind’s Frontier Safety \nFramework (FSF). \n \nSafety Policies: Gemini’s safety policies aim to prevent our Generative AI models from generating \nharmful content, including:  \n \n1.​\nContent related to child sexual abuse material and exploitation \n2.​... Training and Development Evaluation Results:  Results for some of the internal safety evaluations \nconducted during the development phase are listed below. The evaluation results are for automated \nevaluations and not human evaluation or red teaming. Scores are provided as an absolute percentage \nincrease or decrease in performance compared to the indicated model, as described below. Overall,... Gemini 3 Pro outperforms Gemini 2.5 Pro across both safety and tone, while keeping unjustified refusals \nlow. We mark improvements in green and regressions in red. \n \n \nEvaluation1 \nDescription \nGemini 3 Pro \nvs. Gemini 2.5 Pro \nText to Text Safety... Automated content safety evaluation \nmeasuring safety policies \n-10.4% \nMultilingual Safety  \nAutomated safety policy evaluation across \nmultiple languages \n+0.2% (non-egregious) \nImage to Text Safety \nAutomated content safety evaluation \nmeasuring safety policies \n+3.1% (non-egregious)... standard of results. The performance results reported below are computed with improved evaluations \nand thus are not directly comparable with performance results found in previous Gemini model cards. \n \nWe expect variation in our automated safety evaluations results, which is why we review flagged content \nto check for egregious or dangerous material. Our manual review confirmed losses were... overwhelmingly either a) false positives or b) not egregious. \n \nHuman Red Teaming Results: We conduct manual red teaming by specialist teams who sit outside of \nthe model development team. High-level findings are fed back to the model team. For child safety \nevaluations, Gemini 3 Pro satisfied required launch thresholds, which were developed by expert teams... to protect children online and meet Google’s commitments to child safety across our models and \nGoogle products. For content safety policies generally, including child safety, we saw similar or improved \nsafety performance compared to Gemini 2.5 Pro. Compared to 2.5 Pro, the scope of red teaming was \nexpanded to cover more potential issues outside of our strict policies, and found no egregious... concerns. \n \nRisks and Mitigations: Safety and responsibility was built into Gemini 3 Pro throughout the training and \ndeployment lifecycle, including pre-training, post-training, and product-level mitigations. Mitigations \ninclude, but are not limited to:  \n \n●​\ndataset filtering;  \n●​... conditional pre-training; \n●​\nsupervised fine-tuning; \n●​\nreinforcement learning from human and critic feedback; \n●​\nsafety policies and desiderata; \n●​\nproduct-level mitigations such as safety filtering. \n \nThe main risks for Gemini 3 Pro are: a) jailbreak vulnerability (improved compared to Gemini 2.5 Pro but \nstill an open research problem), and b) possible degradation in multi-turn conversations. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n7... Frontier Safety \n \nWe evaluated Gemini 3 Pro as outlined in our latest Frontier Safety Framework (September-2025), \nand found that it did not reach any critical capability levels as outlined in the table below:   \n \nDomain \nKey Results for Gemini 3 Pro  \nCCL  \nCCL \nreached?"
          },
          {
            "snippetId": "risk-mitigations-snippet-3",
            "url": "https://huggingface.co/datasets/multimodalart/google-gemini-3-pro-pre-release-model-card",
            "snippet": "# Gemini 3 Pro - Model Card\n\n*Model Cards* *are intended to provide essential information on Gemini models, including known limitations, mitigation approaches, and safety performance. Model cards may be updated from*\n\n*time-to-time; for example, to include updated evaluations as the model is improved or revised. See the* *Google DeepMind site* *for a comprehensive list of model cards.*... This model card includes more essential information about the Gemini 3 family of models than previous model cards did. We hope more information about the training dataset, distribution, and intended uses will empower developers with deeper insights and help build more robust and responsible downstream applications.\n\n*Published / Model Release: November 2025*... ## Distribution\n\nThe Gemini family of models, including Gemini 3 Pro, are distributed in the following channels; respective documentation shared in line:\n\nOur models are available to downstream providers via an application program interface (API) and subject to relevant terms of use. There is no required hardware or software to use the model. For AI Studio and Gemini API, see the Gemini API Additional Terms of Service; for Vertex AI, see Google Cloud Platform Terms of Service. For more information, see Gemini Model API instructions and Gemini API in Vertex AI quickstart.... **Known Limitations:** Gemini 3 Pro may exhibit some of the general limitations of foundation models, such as hallucinations. There may also be occasional slowness or timeout issues. The knowledge cutoﬀ date for Gemini 3 Pro was January 2025.... ## Ethics and Content Safety\n\n**Evaluation Approach:** Gemini 3 Pro was developed in partnership with internal safety, security, and responsibility teams. A range of evaluations and red teaming activities were conducted to help improve the model and inform decision-making. These evaluations and activities align with Google's AI Principles and responsible AI approach, as well as Google's Generative AI policies (e.g. Gen AI Prohibited Use Policy and the Gemini API Additional Terms of Service).... Evaluation types included but were not limited to:\n\n**Training/Development Evaluations**including automated and human evaluations carried out continuously throughout and after the model's training, to monitor its progress and performance; **Human Red Teaming**conducted by specialist teams who sit outside of the model development team, across the policies and desiderata, deliberately trying to spot weaknesses and ensure the model adheres to safety policies and desired outcomes; **Automated Red Teaming**to dynamically evaluate Gemini for safety and security considerations at scale, complementing human red teaming and static evaluations; **Ethics & Safety Reviews**were conducted ahead of the model's release... **Training and Development Evaluation Results:** Results for some of the internal safety evaluations conducted during the development phase are listed below. The evaluation results are for automated evaluations and not human evaluation or red teaming. Scores are provided as an absolute percentage increase or decrease in performance compared to the indicated model, as described below. Overall, Gemini 3 Pro outperforms Gemini 2.5 Pro across both safety and tone, while keeping unjustiﬁed refusals low. We mark improvements in green and regressions in red.... We continue to improve our internal evaluations, including reﬁning automated evaluations to reduce false positives and negatives, as well as update query sets to ensure balance and maintain a high\n\n1The ordering of evaluations in this table has changed from previous iterations of the 2.5 Flash-Lite model card in order to list safety evaluations together and improve readability. The type of evaluations listed have remained the same.... **Human Red Teaming Results:** We conduct manual red teaming by specialist teams who sit outside of the model development team. High-level ﬁndings are fed back to the model team. For child safety evaluations, Gemini 3 Pro satisﬁed required launch thresholds, which were developed by expert teams to protect children online and meet Google's commitments to child safety across our models and Google products.... For content safety policies generally, including child safety, we saw similar or improved safety performance compared to Gemini 2.5 Pro. Compared to 2.5 Pro, the scope of red teaming was expanded to cover more potential issues outside of our strict policies, and found no egregious concerns.\n\n**Risks and Mitigations:** Safety and responsibility was built into Gemini 3 Pro throughout the training and deployment lifecycle, including pre-training, post-training, and product-level mitigations. Mitigations include, but are not limited to:... - dataset ﬁltering;\n\n- conditional pre-training;\n\n- supervised ﬁne-tuning;\n\n- reinforcement learning from human and critic feedback;\n\n- safety policies and desiderata;\n\n- product-level mitigations such as safety ﬁltering.\n\nThe main risks for Gemini 3 Pro are: a) jailbreak vulnerability (improved compared to Gemini 2.5 Pro but still an open research problem), and b) possible degradation in multi-turn conversations.... ## Frontier Safety\n\nWe evaluated Gemini 3 Pro as outlined in our latest Frontier Safety Framework (September-2025), and found that it did not reach any critical capability levels as outlined in the table below:"
          },
          {
            "snippetId": "risk-mitigations-snippet-4",
            "url": "https://ai.google.dev/gemini-api/docs/changelog",
            "snippet": "This page documents updates to the Gemini API.\n\n## November 20, 2025\n\n- Released Gemini 3 Pro Image Preview,\n\n`gemini-3-pro-image-preview`, the next iteration to the Nano Banana model. Read the Image generation page for more details.... ## November 18, 2025\n\nLaunched the first Gemini 3 series model,\n\n`gemini-3-pro-preview`, our state-of-the-art reasoning and multimodal understanding model with powerful agentic and coding capabilities.\n\nIn addition to improvements in intelligence and performance, Gemini 3 Pro Preview introduces new behavior around:\n\nRead the Gemini 3 Developer Guide for migration, new features, and specs.... ## September 25, 2025\n\nReleased Gemini Robotics-ER 1.5 model in preview. See the Robotics overview to learn about how to use the model for your robotics application.\n\nLaunched following preview models:\n\n`gemini-2.5-flash-preview-09-2025`\n\n`gemini-2.5-flash-lite-preview-09-2025`\n\nSee the Models page for details.... ## June 17, 2025\n\n- Released\n\n`gemini-2.5-pro`, the stable version of our most powerful model, now with adaptive thinking. To learn more, see Gemini 2.5 Pro and Thinking.\n\n`gemini-2.5-pro-preview-05-06`will be redirected to... **Model updates:**\n\n- Released\n\n`gemini-2.5-flash-preview-05-20`, a Gemini preview model optimized for price-performance and adaptive thinking. To learn more, see Gemini 2.5 Flash Preview and Thinking.\n\n- Released the\n\n`gemini-2.5-pro-preview-tts`and... ## May 7, 2025\n\n- Released\n\n`gemini-2.0-flash-preview-image-generation`, a preview model for generating and editing images. To learn more, see Image generation and Gemini 2.0 Flash Preview Image Generation.\n\n## May 6, 2025\n\n- Released\n\n`gemini-2.5-pro-preview-05-06`, a new version of our most powerful model, with improvements on code and function calling.\n\n`gemini-2.5-pro-preview-03-25`will automatically point to the new version of the model.... ## March 12, 2025\n\n**Model updates:**\n\n- Launched an experimental Gemini 2.0 Flash model capable of image generation and editing.\n\n- Released\n\n`gemma-3-27b-it`, available on AI Studio and through the Gemini API, as part of the Gemma 3 launch.\n\n**API updates:**\n\n- Added support for YouTube URLs as a media source.\n\n- Added support for including an inline video of less than 20MB.... ## October 3, 2024\n\n**Model updates:**\n\n- Released\n\n`gemini-1.5-flash-8b-001`, a stable version of our smallest Gemini API model.... ## September 24, 2024\n\n**Model updates:**\n\n- Released\n\n`gemini-1.5-pro-002`and\n\n`gemini-1.5-flash-002`, two new stable versions of Gemini 1.5 Pro and 1.5 Flash, for general availability.... - Updated the\n\n`gemini-1.5-pro-latest`model code to use\n\n`gemini-1.5-pro-002`and the\n\n`gemini-1.5-flash-latest`model code to use\n\n`gemini-1.5-flash-002`.\n\n- Released... `gemini-1.5-flash-8b-exp-0924`to replace\n\n`gemini-1.5-flash-8b-exp-0827`.\n\n- Released the civic integrity safety filter for the Gemini API and AI Studio.\n\n- Released support for two new parameters for Gemini 1.5 Pro and 1.5 Flash in\n\nPython and NodeJS:\n\n`frequencyPenalty`and\n\n`presencePenalty`.... ## August 27, 2024\n\n**Model updates:**\n\n- Released the following\n\nexperimental models:\n\n`gemini-1.5-pro-exp-0827`\n\n`gemini-1.5-flash-exp-0827`\n\n`gemini-1.5-flash-8b-exp-0827`... ## August 9, 2024\n\n**API updates:**\n\n- Added support for PDF processing.\n\n## August 5, 2024\n\n**Model updates:**\n\n- Fine-tuning support released for Gemini 1.5 Flash.\n\n## August 1, 2024\n\n**Model updates:**\n\n- Released\n\n`gemini-1.5-pro-exp-0801`, a new experimental version of Gemini 1.5 Pro.... ## March 19, 2024\n\n**Model updates:**\n\n- Added support for tuning Gemini 1.0 Pro in Google AI Studio or with the Gemini API."
          },
          {
            "snippetId": "risk-mitigations-snippet-5",
            "url": "https://www.studocu.com/en-gb/document/university-of-east-london/financial-accounting/gemini-3-pro-model-card-insights-safety-evaluations-nov-2025/146206142",
            "snippet": "- Evaluation Methods: The model undergoes rigorous testing across benchmarks to assess its reasoning and multimodal performance.\n\n- Safety Policies: Strict guidelines are in place to prevent harmful content generation, ensuring responsible AI use.\n\n- Intended Applications: Designed for complex problem-solving, the model excels in areas requiring advanced reasoning and creativity.\n\n## Preview text\n\nModel card published: November, 2025... ## Gemini 3 Pro\n\n## Model Card\n\n### Gemini 3 Pro - Model Card\n\nModel Cards are intended to provide essential information on Gemini models, including known limitations, mitigation approaches, and safety performance. Model cards may be updated from time-to-time; for example, to include updated evaluations as the model is improved or revised. See the Google DeepMind site for a comprehensive list of model cards.... This model card includes more essential information about the Gemini 3 family of models than previous model cards did. We hope more information about the training dataset, distribution, and intended uses will empower developers with deeper insights and help build more robust and responsible downstream applications.\n\nPublished / Model Release: November 2025... #### Model Information\n\nDescription: Gemini 3 Pro is the next generation in the Gemini series of models, a suite of highly-capable, natively multimodal, reasoning models. Gemini 3 Pro is now Google’s most advanced model for complex tasks, and can comprehend vast datasets, challenging problems from different information sources, including text, audio, images, video, and entire code repositories.... Architecture: Gemini 3 Pro is a sparse mixture-of-experts (MoE) (Clark et al., 2022; Du et al., 2021; Fedus et al., 2021; Jiang et al., 2024, Lepikhin et al., 2020; Riquelme et al., 2021; Roller et al., 2021; Shazeer et al., 2017 ) transformer-based model (Vaswani et al., 2017) with native multimodal support for text, vision, and audio inputs.... #### Distribution\n\nThe Gemini family of models, including Gemini 3 Pro, are distributed in the following channels; respective documentation shared in line:\n\n● Gemini App ● Google Cloud / Vertex AI ● Google AI Studio ● Gemini API ● Google AI Mode ● Google Antigravity... Our models are available to downstream providers via an application program interface (API) and subject to relevant terms of use. There is no required hardware or software to use the model. For AI Studio and Gemini API, see the Gemini API Additional Terms of Service; for Vertex AI, see Google Cloud Platform Terms of Service. For more information, see Gemini Model API instructions and Gemini API in Vertex AI quickstart.... Training and Development Evaluation Results: Results for some of the internal safety evaluations conducted during the development phase are listed below. The evaluation results are for automated evaluations and not human evaluation or red teaming. Scores are provided as an absolute percentage increase or decrease in performance compared to the indicated model, as described below. Overall, Gemini 3 Pro outperforms Gemini 2 Pro across both safety and tone, while keeping unjustified refusals low. We mark improvements in green and regressions in red.... Evaluation 1 Description Gemini 3 Pro vs. Gemini 2 Pro\n\nText to Text Safety Automated content safety evaluation measuring safety policies -10%\n\nMultilingual Safety Automated safety policy evaluation across multiple languages +0% (non-egregious)\n\nImage to Text Safety Automated content safety evaluation measuring safety policies +3% (non-egregious)... We expect variation in our automated safety evaluations results, which is why we review flagged content to check for egregious or dangerous material. Our manual review confirmed losses were overwhelmingly either a) false positives or b) not egregious.... Human Red Teaming Results: We conduct manual red teaming by specialist teams who sit outside of the model development team. High-level findings are fed back to the model team. For child safety evaluations, Gemini 3 Pro satisfied required launch thresholds, which were developed by expert teams to protect children online and meet Google’s commitments to child safety across our models and Google products.... For content safety policies generally, including child safety, we saw similar or improved safety performance compared to Gemini 2 Pro. Compared to 2 Pro, the scope of red teaming was expanded to cover more potential issues outside of our strict policies, and found no egregious concerns.\n\nRisks and Mitigations: Safety and responsibility was built into Gemini 3 Pro throughout the training and deployment lifecycle, including pre-training, post-training, and product-level mitigations. Mitigations include, but are not limited to:... ● dataset filtering; ● conditional pre-training; ● supervised fine-tuning; ● reinforcement learning from human and critic feedback; ● safety policies and desiderata; ● product-level mitigations such as safety filtering.\n\nThe main risks for Gemini 3 Pro are: a) jailbreak vulnerability (improved compared to Gemini 2 Pro but still an open research problem), and b) possible degradation in multi-turn conversations."
          }
        ],
        "subsectionChecks": [
          {
            "name": "Risk Mitigations",
            "score": 1,
            "explanation": "Safety and responsibility was built into Gemini 3 Pro throughout the training and deployment lifecycle, including pre-training, post-training, and product-level mitigations."
          }
        ]
      }
    ]
  }
}